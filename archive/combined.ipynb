{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1eb713d-4a4c-4104-824c-86a6b483b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import imutils\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from scipy.stats import mode\n",
    "from collections import OrderedDict\n",
    "from itertools import zip_longest\n",
    "from imutils import perspective\n",
    "from typing import List\n",
    "from operator import attrgetter\n",
    "from scipy.stats import zscore\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "from imutils.perspective import order_points\n",
    "from shapely import LineString\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import imutils\n",
    "import pandas as pd\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from alice.utils import *\n",
    "from alice.utils.geometry import *\n",
    "from alice.craft import Craft\n",
    "from alice.mask import visualise_predictions, predictor\n",
    "from alice.config import PROCESSING_INPUT_DIR, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e035d580-044f-4d39-8ca8-eb84cd0eabee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = [Path('/Users/ben/Projects/NaturalHistoryMuseum/ALICE/ALICE/data/images/2048x/011244568_additional_1.jpeg'), Path('/Users/ben/Projects/NaturalHistoryMuseum/ALICE/ALICE/data/images/2048x/011244568_additional_2.jpeg'), Path('/Users/ben/Projects/NaturalHistoryMuseum/ALICE/ALICE/data/images/2048x/011244568_additional_3.jpeg'), Path('/Users/ben/Projects/NaturalHistoryMuseum/ALICE/ALICE/data/images/2048x/011244568_additional_4.jpeg')]\n",
    "specimen_id = '011244568'\n",
    "# paths = [PROCESSING_INPUT_DIR / f'Tri434014_additional_{i}.JPG' for i in range(1,5)]\n",
    "\n",
    "paths = [PROCESSING_INPUT_DIR / f'011250151_additional({i}).JPG' for i in range(1,5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e34e006-bc96-4413-9a37-659a0898198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class LabelValid(Enum):\n",
    "    VALID = 0\n",
    "    INVALID_QUADRILATERAL = 1\n",
    "    NONDETECTED_LABELS = 2\n",
    "    INVALID_SHAPE = 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e3ea1-997f-453e-8827-aeadc57ad539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/Projects/NaturalHistoryMuseum/ALICE/CRAFT-pytorch/.venv/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Base():\n",
    "\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.image_height, self.image_width = image.shape[:2]\n",
    "        \n",
    "    def visualise(self, image=None):\n",
    "        image = self.image.copy() if image is None else image\n",
    "        return self._visualise(image)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _visualise(self, image):\n",
    "        return None\n",
    "\n",
    "    def display(self):\n",
    "        image = self.visualise()\n",
    "        plt.imshow(image), plt.show()  \n",
    "\n",
    "class Quadrilateral(Base):\n",
    "    def __init__(self, vertices, image, is_approx=False):\n",
    "        super().__init__(image)\n",
    "        self.is_approx = is_approx\n",
    "        \n",
    "        # Closest point to the bottom of the canvas\n",
    "        self.closest_point = self.get_closest_point(vertices)\n",
    "\n",
    "        # Vertices are assigned to a,b,c,d\n",
    "        # A will be the closest point (with the maximum y value), with the points\n",
    "        # ordered counter clockwise, with b being the next corner counter clockwise\n",
    "        # A & C will be opposite each other; B & D opposite\n",
    "        self.vertices = OrderedDict(zip(['a', 'b', 'c', 'd'], iter_list_from_value(vertices, self.closest_point)))\n",
    "        \n",
    "        # Loop through vertices, creating edges names a_b, b_c etc.,\n",
    "        self.edges = OrderedDict([(\n",
    "            f'{k1}_{k2}', LineString([\n",
    "                self.vertices[k1], \n",
    "                self.vertices[k2]\n",
    "            ])) for k1, k2 in pairwise(list(self.vertices.keys()))\n",
    "        ])\n",
    "        self.angles = self.get_corner_angles()\n",
    "\n",
    "    def get_closest_point(self, vertices):\n",
    "        \"\"\"\n",
    "        Closest point is the bottom corner nearest the center point of the image\n",
    "        \"\"\"\n",
    "        center = round(self.image_width / 2)\n",
    "        vertices = np.array(vertices)\n",
    "        bottom_corners = vertices[np.argpartition(vertices[:, 1], -2)[-2:]]\n",
    "        x_offset_from_center = np.abs(bottom_corners[:, 0] - center)\n",
    "        closest_point = bottom_corners[np.argmin(x_offset_from_center)]\n",
    "        return tuple(closest_point)\n",
    "\n",
    "    def get_corner_angles(self):\n",
    "        angles = {}\n",
    "        maxv = len(self.vertices) - 1\n",
    "        vertice_labels = list(self.vertices.keys())\n",
    "        for i, vertice in enumerate(vertice_labels):    \n",
    "            next_vertice = vertice_labels[i+1 if i < maxv else 0]\n",
    "            prev_vertice = vertice_labels[i-1 if i > 0 else maxv]\n",
    "            vertices = np.array([\n",
    "                self.vertices[prev_vertice],\n",
    "                self.vertices[vertice],\n",
    "                self.vertices[next_vertice]\n",
    "            ])\n",
    "            angle = calculate_angle(*vertices.ravel())\n",
    "            angles[vertice] = angle        \n",
    "        return angles\n",
    "\n",
    "    def is_wellformed_label_shape(self):\n",
    "        \"\"\"\n",
    "        Validate the label shape, 4 corners & opposite angles be within 15 degrees\n",
    "        \"\"\"\n",
    "        # Corners must be in this range\n",
    "        valid_angle = {\n",
    "            'min': 30,\n",
    "            'max': 150\n",
    "        }\n",
    "        # Oppos corners should not have more than this angle difference\n",
    "        # Otherwise boxed is squashes\n",
    "        valid_angle_diff = 15\n",
    "        if len(self.vertices) != 4:\n",
    "            return False\n",
    "            \n",
    "        angles = np.array(list(self.angles.values()))\n",
    "        min_angle, max_angle = min_max(angles)\n",
    "        if min_angle < valid_angle['min'] or max_angle > valid_angle['max']:\n",
    "            return False\n",
    "            \n",
    "        oppos_corners = [('a', 'c'), ('b', 'd')]\n",
    "        angle_diff = max([abs(self.angles[i] - self.angles[j]) for i,j in oppos_corners])  \n",
    "        return angle_diff < valid_angle_diff\n",
    "\n",
    "    def nearest_corner_is_good(self):\n",
    "        \"\"\"\n",
    "        See if the nearest corner has acceptable angle range\n",
    "        \"\"\"\n",
    "        # Stricter upper bounds than the valid_angle above; all other corners are based\n",
    "        # on thise one, so it needs to be good\n",
    "        lower_bound = 100\n",
    "        upper_bound = 130\n",
    "        return lower_bound <= self.angles['a'] <= upper_bound\n",
    "\n",
    "    @property\n",
    "    def x_length(self):\n",
    "        return round(max([self.edges['a_b'].length, self.edges['c_d'].length]))\n",
    "\n",
    "    @property\n",
    "    def y_length(self):\n",
    "        return round(max([self.edges['b_c'].length, self.edges['d_a'].length]))\n",
    "\n",
    "    def _visualise(self, image):\n",
    "        edge_color = (255, 255, 0) if self.is_approx else (0, 255, 0)\n",
    "        for edge in self.edges.values():\n",
    "            p = np.array(edge.coords).astype(np.int32)\n",
    "            cv2.line(image, p[0], p[1], edge_color, 5)\n",
    "        for point in self.vertices.values():\n",
    "            pt = np.array(point).astype(np.int32)\n",
    "            cv2.circle(image, pt, 5, (255,0,0), 10)\n",
    "\n",
    "        pt = np.array(self.closest_point).astype(np.int32)\n",
    "        cv2.circle(image, pt, 5, (255,0,255), 12)            \n",
    "        return image\n",
    "\n",
    "class Label(Base):\n",
    "\n",
    "    \"\"\"\n",
    "    Representing a single label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_mask):\n",
    "        self.valid = LabelValid.VALID\n",
    "        super().__init__(label_mask.image)\n",
    "        self.label_mask = label_mask\n",
    "        polygon = label_mask.get_polygon(epsilon=5)\n",
    "        self.vertices = approx_best_fit_ngon(polygon)        \n",
    "        self.quad = self._get_quadrilateral()        \n",
    "\n",
    "    def _get_quadrilateral(self):\n",
    "\n",
    "        quad = Quadrilateral(self.vertices, self.image)\n",
    "        if quad.is_wellformed_label_shape():\n",
    "            return quad\n",
    "\n",
    "        logger.debug(\"Quad not well formed shape\")\n",
    "        logger.debug_image(quad.visualise(), 'not-wellformed-quad')\n",
    "        \n",
    "        if quad.nearest_corner_is_good():\n",
    "            logger.debug(\"Guestimating quad from good nearest corner\")\n",
    "            closest_edges = [quad.edges[e] for e in ['a_b', 'd_a']]\n",
    "            vertices = self.approx_quadrilateral_from_closest_edges(closest_edges) \n",
    "            approx_quad = Quadrilateral(vertices, self.image, is_approx=True)\n",
    "            \n",
    "            if approx_quad.is_wellformed_label_shape(): \n",
    "                logger.debug_image(approx_quad.visualise(), 'approx-quad-wellformed')\n",
    "                return approx_quad\n",
    "            else:\n",
    "                logger.debug(\"Approximted quad not well formed\")\n",
    "                \n",
    "        else:\n",
    "            logger.debug(\"Cannot guesstimate quad - nearest corner not suitable\")\n",
    "\n",
    "        self.set_valid(LabelValid.INVALID_QUADRILATERAL)\n",
    "\n",
    "    def approx_quadrilateral_from_closest_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Approximate the quadrilateral vertices, from two edges\n",
    "        \n",
    "        We create a line with same slope, and then calculate the position intersecting\n",
    "        the mask at the greatest perpendicular distance from the initial edge\n",
    "        \n",
    "        Intersection of these four lines will be the quadrilateral vertices\n",
    "        \n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        # Loop through the two good edges, creating a line with the same slope\n",
    "        # which interesect the further perpendicular edge of the mask\n",
    "        for edge in edges:\n",
    "            extended_edge = extend_line(edge, self.image_width * self.image_height)\n",
    "            furthest_point = get_furthest_point_perpendicular_from_line(extended_edge, self.label_mask.edge_points())\n",
    "            new_line = get_line_at_point(extended_edge, furthest_point, self.image_width)\n",
    "            lines.append((extended_edge, new_line))\n",
    "    \n",
    "        # Calculate new vertices from line intersections\n",
    "        vertices = []\n",
    "        for line in lines[0]:\n",
    "            for perpendicular_line in lines[1]:\n",
    "                if intersection := line.intersection(perpendicular_line):\n",
    "                    vertices.append((int(intersection.x), int(intersection.y)))  \n",
    "    \n",
    "        # FIXME: The accuracy of this can be improved by adding perspective correction    \n",
    "        ordered_vertices = cv2.convexHull(np.array(vertices), clockwise=False, returnPoints=True)\n",
    "        # Convert to list of tuples\n",
    "        return [tuple(point[0]) for point in ordered_vertices]            \n",
    "\n",
    "    def _visualise(self, image):\n",
    "        if self.quad:\n",
    "            return self.quad.visualise(image)\n",
    "\n",
    "        # We don't have a quad, so label won;t be used - mark with red top\n",
    "        cv2.rectangle(image, (0, 0), (self.image_width, 10), (255, 0, 0), -1)\n",
    "\n",
    "        for point in self.vertices:\n",
    "            pt = np.array(point).astype(np.int32)\n",
    "            cv2.circle(image, pt, 5, (255,0,0), 10)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def set_valid(self, valid: LabelValid):\n",
    "        self.valid = valid\n",
    "\n",
    "    def is_valid(self):\n",
    "        return self.valid == LabelValid.VALID\n",
    "\n",
    "    def crop(self, max_shortest_edge, max_longest_edge):\n",
    "\n",
    "        x_is_longest = self.quad.x_length > self.quad.y_length\n",
    "        \n",
    "        if x_is_longest:\n",
    "            x = max_longest_edge\n",
    "            y = max_shortest_edge\n",
    "        else:\n",
    "            x = max_shortest_edge\n",
    "            y = max_longest_edge\n",
    "            \n",
    "        dest = np.float32([\n",
    "            (0, x), #A\n",
    "            (0, 0), #B\n",
    "            (y, 0), #C\n",
    "            (y, x) #D\n",
    "        ])\n",
    "        \n",
    "        src = np.float32(list(self.quad.vertices.values()))\n",
    "        M = cv2.getPerspectiveTransform(src, dest)\n",
    "\n",
    "        image = self.image.copy()\n",
    "        upper_masks = self.label_mask\n",
    "    \n",
    "        cropped = cv2.warpPerspective(self.image, M,(y, x),flags=cv2.INTER_LINEAR)   \n",
    "        return cropped\n",
    "\n",
    "             \n",
    "class LabelMask(Base):\n",
    "    def __init__(self, mask: np.array, image):        \n",
    "        super().__init__(image)\n",
    "        self.mask = mask.astype(np.uint8)\n",
    "\n",
    "    @property\n",
    "    def y_midpoint(self):\n",
    "        \"\"\"\n",
    "        Vertical midpoint of a mask\n",
    "        \"\"\"        \n",
    "        return sum([min(np.where(self.mask == True)[0]), max(np.where(self.mask == True)[0])]) / 2 \n",
    "\n",
    "    @property\n",
    "    def contour(self):\n",
    "        contours, _ = cv2.findContours(self.mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # If we have multiple contours, only use the largest one\n",
    "        sorted_countors = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        return sorted_countors[0]\n",
    "        \n",
    "    def get_polygon(self, epsilon=None):\n",
    "        \"\"\"\n",
    "        Get polygon around the mask\n",
    "\n",
    "        Note: otherwise approx_best_fit_ngon takes many seconds so requires \n",
    "        low epsilon < 10 otherwise approx vertices are out \n",
    "        epsilon=5 works well\n",
    "        \"\"\"\n",
    "        if not epsilon:\n",
    "            epsilon = 0.02 * cv2.arcLength(self.contour, True)\n",
    "            \n",
    "        return cv2.approxPolyDP(self.contour, epsilon, True)\n",
    "\n",
    "    def edges(self) -> np.array:\n",
    "        \"\"\"\n",
    "        Get edges of a mask\n",
    "        \"\"\"\n",
    "        # Diff will reduce width by 1, so prepend with extra column of 0s\n",
    "        return np.diff(self.mask, prepend=np.zeros(self.image_height)[0])  \n",
    "\n",
    "    def edge_points(self) -> List:   \n",
    "        \"\"\"\n",
    "        Get the edges \n",
    "        \"\"\"    \n",
    "        # Find the indices of True values in the mask, and return row col (points)\n",
    "        return [(col, row) for row, col in np.argwhere(self.edges())]  \n",
    "\n",
    "    def _visualise(self, image):\n",
    "        contour = self.contour\n",
    "        image = cv2.drawContours(image, contour, -1, (255, 255, 0), 20)\n",
    "        cv2.drawContours(image, [self.get_polygon()], -1, (0, 255, 0), 2)  # Draw in green        \n",
    "        return image\n",
    "\n",
    "    def subtract_mask(self, subtraction_mask):\n",
    "        \"\"\"\n",
    "        Subtract mask from mask\n",
    "        \"\"\"\n",
    "        self.mask = cv2.bitwise_and(self.mask, cv2.bitwise_not(subtraction_mask))\n",
    "\n",
    "    def fill_image(self, mask):\n",
    "        self.image[mask] = [255, 255, 255]\n",
    "        plt.imshow(self.image), plt.show() \n",
    "\n",
    "class LabelMasks(Base):\n",
    "\n",
    "    min_mask_size = 1500\n",
    "    mask_model = predictor\n",
    "\n",
    "    def __init__(self, image):\n",
    "        super().__init__(image)\n",
    "        self.predictions = self.mask_model(self.image)\n",
    "        self.label_masks = self._predictions_to_label_masks()\n",
    "        self._clean_obscured_masks()\n",
    "        \n",
    "    def _predictions_to_label_masks(self):\n",
    "        masks = self.predictions.get('instances').to(\"cpu\").pred_masks.numpy()\n",
    "        masks = self.filter_small_masks(masks)    \n",
    "        label_masks = [LabelMask(m, self.image) for m in masks]\n",
    "        # Sort by mask y midpoint\n",
    "        label_masks.sort(key = attrgetter('y_midpoint'))        \n",
    "        return label_masks\n",
    "\n",
    "    def get_higher_labels_mask(self, label_index):\n",
    "        \"\"\"\n",
    "        Get a mask representing all labels above the label_index\n",
    "        \"\"\"\n",
    "        # Get masks higher up the label stack (lower masks have index 0)\n",
    "        higher_masks = self.label_masks[label_index+1:]\n",
    "        combined_mask = np.zeros((self.image_height, self.image_width), dtype=np.uint8)\n",
    "        for mask in higher_masks:\n",
    "            cv2.fillPoly(combined_mask, [mask.get_polygon()], 255)    \n",
    "        return combined_mask\n",
    "    \n",
    "    def _clean_obscured_masks(self):\n",
    "        \"\"\"\n",
    "        Some detected areas are actually parts of masks higher in the stack\n",
    "        So filter out obscured areas\n",
    "        \"\"\"\n",
    "        for label_index, mask in enumerate(self.label_masks):\n",
    "            higher_labels_mask = self.get_higher_labels_mask(label_index)\n",
    "            mask.subtract_mask(higher_labels_mask)\n",
    "            mask.fill_image(higher_labels_mask)\n",
    "\n",
    "    def filter_small_masks(self, masks: np.array):\n",
    "        return [m for m in masks if np.count_nonzero(m) > self.min_mask_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_masks)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.label_masks[i]        \n",
    "\n",
    "    def _visualise(self, image):\n",
    "        return visualise_predictions(image, self.predictions)\n",
    "        \n",
    "class SpecimenView(Base):\n",
    "\n",
    "    \"\"\"\n",
    "    A view of the specimen \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path: Path):\n",
    "        image = cv2.imread(str(path))\n",
    "        super().__init__(image)\n",
    "        self.label_masks = LabelMasks(image)\n",
    "\n",
    "        # label_mask = self.label_masks[0]\n",
    "        # label = Label(label_mask)\n",
    "        \n",
    "        # # label_mask.log()\n",
    "        \n",
    "        self.labels = [Label(label_mask) for label_mask in self.label_masks]\n",
    "\n",
    "        for label in self.labels:\n",
    "            label.display()\n",
    "\n",
    "class Specimen():\n",
    "    def __init__(self, specimen_id, paths: List[Path]):\n",
    "\n",
    "        logger.set_specimen_id(specimen_id)\n",
    "        # paths = [paths[0]]\n",
    "\n",
    "        self.views = [SpecimenView(p) for p in paths]\n",
    "        modal = mode([len(view.labels) for view in self.views]) \n",
    "        for view in self.views:\n",
    "            if len(view.labels) != modal.mode:\n",
    "                for label in view.labels[1:]:\n",
    "                    label.set_valid(LabelValid.NONDETECTED_LABELS)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        for view in self.views:\n",
    "            yield view\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.views)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.views[i]\n",
    "\n",
    "    # def get_labels(self, label_index):\n",
    "\n",
    "    #     # Normalise labels so they are all equal width and height - using the maximum width/height\n",
    "    #     # of the largest label\n",
    "    #     dimensions = np.array([\n",
    "    #         sorted([view.rois[label_index].x_length, view.rois[label_index].y_length]) for view in self.views\n",
    "    #     ])\n",
    "\n",
    "    #     max_shortest_edge = np.max(dimensions[:,0])\n",
    "    #     max_longest_edge = np.max(dimensions[:,1])    \n",
    "\n",
    "    #     labels = []\n",
    "    #     for view in self.views:\n",
    "    #         roi = view.rois[label_index]\n",
    "    #         labels.append(\n",
    "    #             roi.get_normalised_label(view.image, max_longest_edge, max_shortest_edge)\n",
    "    #         )\n",
    "\n",
    "    #     # FIXME: loop through and \n",
    "    #     # First two labels will be opposite way up to last two - rotate the last two 180 degrees\n",
    "    #     # FIXME: This doesn't check the orientation - but this should work either way\n",
    "    #     # labels = labels[:2] + [imutils.rotate_bound(label, 180) for label in labels[2:]]\n",
    "    #     return labels\n",
    "\n",
    "specimen = Specimen(specimen_id, paths)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5e519-0305-4008-b7e4-a584f52fc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modal = mode([len(view.labels) for view in specimen.views]) \n",
    "for view in specimen.views:\n",
    "    if len(view.labels) != modal.mode:\n",
    "        for label in view.labels[1:]:\n",
    "            label.set_valid(LabelValid.NONDETECTED_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406fc57-7850-4988-8502-c63022eb3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, view in enumerate(specimen.views):\n",
    "    print(i)\n",
    "    for label in view.labels:\n",
    "        print(label.valid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172cc12-5b4f-4a10-a2ff-a0bc3664b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InvalidLabel():\n",
    "\n",
    "    valid = LabelValid.NONDETECTED_LABELS\n",
    "\n",
    "    def is_valid(self):\n",
    "        return False\n",
    "\n",
    "        \n",
    "\n",
    "class LabelsView(Base):\n",
    "    def __init__(self):\n",
    "        self._labels = []\n",
    "        \n",
    "    def add_label(self, label):\n",
    "        self._labels.append(label)\n",
    "\n",
    "    def get_cropped(self):\n",
    "        max_shortest_edge, max_longest_edge = self.get_dimensions()\n",
    "        first_landscape = 0\n",
    "        cropped = {}\n",
    "        for i, label in enumerate(self._labels):\n",
    "            if not label.is_valid(): continue\n",
    "\n",
    "            cropped_image = label.crop(max_shortest_edge, max_longest_edge)\n",
    "            h, w = cropped_image.shape[:2]\n",
    "            is_landscape = w > h\n",
    "            # Capture the first landscape label - we'll use this as \n",
    "            # the base to rotate to            \n",
    "            if not first_landscape and is_landscape:\n",
    "                first_landscape = i\n",
    "\n",
    "            cropped[i] = label.crop(max_shortest_edge, max_longest_edge)\n",
    "\n",
    "        # Rotate all images to the first landscape one\n",
    "        rotated = {}\n",
    "        for i in range(len(self._labels)):\n",
    "            if not i in cropped: continue\n",
    "            rotation = (i - first_landscape) * 90\n",
    "            rotated[i] = imutils.rotate_bound(cropped[i], rotation)\n",
    "\n",
    "        return rotated\n",
    "\n",
    "    def iter_valid(self):\n",
    "        for label in self._labels:\n",
    "            if label.is_valid():\n",
    "                yield label\n",
    "\n",
    "    def _get_dimensions_min_max(self):\n",
    "        dimensions = np.array([\n",
    "            (label.quad.x_length, label.quad.y_length) for label in self.iter_valid()\n",
    "        ])\n",
    "        return np.array([min_max(d) for d in dimensions]) \n",
    "        \n",
    "    def get_dimensions(self):\n",
    "        \"\"\"\n",
    "        Get edge dimensions for all labels in the view\n",
    "        \"\"\"\n",
    "        min_maxes = self._get_dimensions_min_max()\n",
    "        min_maxes = self.validate_shape_homogeneity(min_maxes)\n",
    "        return np.max(min_maxes[:,0]), np.max(min_maxes[:,1])        \n",
    "\n",
    "    def validate_shape_homogeneity(self, min_maxes):\n",
    "\n",
    "        if len(min_maxes) <= 1:\n",
    "            return min_maxes\n",
    "            \n",
    "        if len(min_maxes) == 2:\n",
    "            outliers_mask = self._validate_shape_difference(min_maxes)\n",
    "        else:\n",
    "            outliers_mask = self._validate_shape_deviation(min_maxes)\n",
    "            \n",
    "        # Mark these labels as invalid so they won't be included in the merge\n",
    "        for i, label in enumerate(self.iter_valid()):\n",
    "            if not outliers_mask[i]:\n",
    "                print(f\"Marking shape {i} invalid\")\n",
    "                label.set_valid(LabelValid.INVALID_SHAPE)\n",
    "            \n",
    "        # Mask the min maxes value, so outlines won't be used in dimension calculations \n",
    "        return min_maxes[outliers_mask]              \n",
    "\n",
    "    def _validate_shape_difference(self, min_maxes):\n",
    "        \"\"\"\n",
    "        Validate shape lengths are not two disimilar from each other\n",
    "        Used for validating shapes when we just have two labels \n",
    "        \"\"\"\n",
    "        min_diff = np.mean(min_maxes) / 4\n",
    "        # Calculate the maxium different along the edges\n",
    "        diff = np.max(np.diff(min_maxes, axis=1))\n",
    "        if diff > min_diff:\n",
    "            # Create a mask where True is set to the highest value\n",
    "            max_value = np.max(min_maxes[:, 1])\n",
    "            mask = min_maxes[:, 1] == max_value\n",
    "        else:\n",
    "            mask = np.any(min_diff, axis=1)\n",
    "        return mask\n",
    "            \n",
    "    def _validate_shape_deviation(self, min_maxes):\n",
    "        \"\"\"\n",
    "        Validate the deviations in shape, and remove outliers \n",
    "        \"\"\"\n",
    "        # Loop through the min max columns, checking they are within accepted deviations\n",
    "        outliers = np.array([self.get_outliers(data) for data in min_maxes.T])\n",
    "        # Combine both array of outliers using logical and into an outliers_mask\n",
    "        return np.logical_and(outliers[0], outliers[1])\n",
    "\n",
    "    def get_outliers(self, data):\n",
    "        # FIXME: This needs to be more robust\n",
    "        # What about 1/2 images?\n",
    "        # What about scale factor?\n",
    "        # Calculate median deviation\n",
    "        median = np.median(data)\n",
    "        # calculate median absolute deviation\n",
    "        deviation = np.sqrt((data - median)**2)\n",
    "        max_deviation = 300\n",
    "        return deviation < max_deviation\n",
    "\n",
    "labels_views = []\n",
    "\n",
    "for label_index in range(0, modal.mode):\n",
    "    labels_view = LabelsView()\n",
    "    for view in specimen.views:\n",
    "        try:\n",
    "            label = view.labels[label_index]\n",
    "        except IndexError:\n",
    "            # We do not have a label at this index position -\n",
    "            # Will happen if there's no mask, but we want preserve\n",
    "            # the order of other labels so insert InvalidLabel()\n",
    "            label = InvalidLabel()\n",
    "        finally:                        \n",
    "            labels_view.add_label(label)\n",
    "\n",
    "    labels_views.append(labels_view)\n",
    "    \n",
    "    \n",
    "    # for label_index, label in enumerate(view.labels):\n",
    "#         labels_views[label_index].add_label(label)\n",
    "        \n",
    "\n",
    "# FIMXE: Second round - clear different in label sises\n",
    "\n",
    "\n",
    "\n",
    "# for labels_view in labels_views:\n",
    "\n",
    "labels_view = labels_views[1]\n",
    "\n",
    "# dims = labels_view._get_dimensions_min_max()\n",
    "# min_diff = np.min(dims) / 4\n",
    "# if len(dims) == 2:\n",
    "#     # Calculate the maxium different along the edges\n",
    "#     diff = np.max(np.diff(dims, axis=1))\n",
    "    \n",
    "#     if diff > min_diff:\n",
    "#         # If the diff is greater than min difference, return a boolean array\n",
    "#         # with the True value the dimension with the longest edge\n",
    "#         longest = np.argmax(dims[:, 1])\n",
    "#         return np.array([i == longest for i in range(2)], dtype=bool)\n",
    "    \n",
    "\n",
    "\n",
    "# print(np.dot(dims))\n",
    "\n",
    "# print(len(dims))\n",
    "\n",
    "# for label in labels_view.iter_valid():    \n",
    "#     print(label.valid)\n",
    "#     # if label.is_valid():\n",
    "#     label.display()\n",
    "\n",
    "# for labels_view in labels_views:\n",
    "\n",
    "labels_view = labels_views[2]\n",
    "\n",
    "images = labels_view.get_cropped()\n",
    "\n",
    "for image in images.values():\n",
    "    plt.imshow(image), plt.show()\n",
    "    \n",
    "    # dims = labels_view.get_dimensions()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e400942-2cee-4173-9524-6557ed2075de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "min_maxes = np.array([min_max(d) for d in dims])\n",
    "\n",
    "# z_scores = stats.zscore(min_maxes[:,1])\n",
    "# outliers = [(x, z) for x, z in zip(min_maxes[:,1], z_scores) if abs(z) > 2]\n",
    "# print(outliers)\n",
    "\n",
    "def get_outliers(data):\n",
    "    median = np.median(data)\n",
    "    # calculate median absolute deviation\n",
    "    deviation = np.sqrt((data - median)**2)\n",
    "    max_deviation = np.max([np.median(deviation) * 2, 100])\n",
    "    return deviation < max_deviation\n",
    "\n",
    "outliers = np.array([get_outliers(data) for data in min_maxes.T])\n",
    "merged_outliers = np.logical_and(outliers[0], outliers[1])\n",
    "print(merged_outliers)\n",
    "\n",
    "\n",
    "# data = min_maxes[:,1]\n",
    "\n",
    "# median = np.median(data)\n",
    "\n",
    "\n",
    "\n",
    "# z_score = deviation < max_deviation\n",
    "# print(z_score)\n",
    "\n",
    "# print(deviation)\n",
    "# print(np.sum(deviation))\n",
    "# print(np.median(deviation))\n",
    "# print(deviation)\n",
    "# diff = \n",
    "# print(diff)\n",
    "\n",
    "# print(np.max(data))\n",
    "\n",
    "# diff = np.sqrt((data - median)**2)\n",
    "# med_abs_deviation = np.median(diff)\n",
    "\n",
    "# print(data)\n",
    "# print(diff)\n",
    "# print(med_abs_deviation)\n",
    "\n",
    "\n",
    "\n",
    "# z_score = diff < med_abs_deviation * 2\n",
    "# print(z_score)\n",
    "\n",
    "# print(np.std(data))\n",
    "\n",
    "\n",
    "# diff = np.sum((data - median)**2, axis=-1)\n",
    "# diff = np.sqrt(diff)\n",
    "# print(diff)\n",
    "# med_abs_deviation = np.median(diff)\n",
    "# print(med_abs_deviation)\n",
    "# q1 = np.percentile(data, 25)\n",
    "# q3 = np.percentile(data, 75)\n",
    "\n",
    "# iqr = q3 - q1\n",
    "# lower_bound = q1 - 0.8 * iqr\n",
    "# upper_bound = q3 + 0.8 * iqr\n",
    "# outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
    "\n",
    "# print(q1)\n",
    "# print(q3)\n",
    "# print(upper_bound)\n",
    "\n",
    "# print(data)\n",
    "# # print(iqr)\n",
    "# print(outliers)\n",
    "\n",
    "# mean = np.mean(data)\n",
    "# std_dev = np.std(data)\n",
    "# print(mean)\n",
    "# print(std_dev)\n",
    "\n",
    "# x = np.array([1179,1418,1138])\n",
    "# print(np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dffdf83-f502-4ac9-a9e6-2f8be889d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Base():\n",
    "\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "\n",
    "    def visualise(self, image=None):\n",
    "        image = self.image.copy() if image is None else image\n",
    "        return self._visualise(image)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _visualise(self, image):\n",
    "        return None\n",
    "    \n",
    "    def log(self):\n",
    "        image = self.visualise()\n",
    "        plt.imshow(image), plt.show()  \n",
    "        \n",
    "        \n",
    "class QuadrilateralROI(Base):\n",
    "    def __init__(self, vertices, image, is_approx=False):\n",
    "        super().__init__(image)\n",
    "        \n",
    "        # Closest point to the bottom of the canvas\n",
    "        self.closest_point = self.get_closest_point(vertices)\n",
    "\n",
    "        # Vertices are assigned to a,b,c,d\n",
    "        # A will be the closest point (with the maximum y value), with the points\n",
    "        # ordered counter clockwise, with b being the next corner counter clockwise\n",
    "        # A & C will be opposite each other; B & D opposite\n",
    "        self.vertices = OrderedDict(zip(['a', 'b', 'c', 'd'], iter_list_from_value(vertices, self.closest_point)))\n",
    "        \n",
    "        # Loop through vertices, creating edges names a_b, b_c etc.,\n",
    "        self.edges = OrderedDict([(\n",
    "            f'{k1}_{k2}', LineString([\n",
    "                self.vertices[k1], \n",
    "                self.vertices[k2]\n",
    "            ])) for k1, k2 in pairwise(list(self.vertices.keys()))\n",
    "        ])\n",
    "        self.angles = self.get_corner_angles()\n",
    "\n",
    "    def get_closest_point(self, vertices):\n",
    "        \"\"\"\n",
    "        Closest point is the bottom corner nearest the center point of the image\n",
    "        \"\"\"\n",
    "        center = round(self.image.shape[1] / 2)\n",
    "        vertices = np.array(vertices)\n",
    "        bottom_corners = vertices[np.argpartition(vertices[:, 1], -2)[-2:]]\n",
    "        x_offset_from_center = np.abs(bottom_corners[:, 0] - center)\n",
    "        closest_point = bottom_corners[np.argmin(x_offset_from_center)]\n",
    "        return tuple(closest_point)\n",
    "\n",
    "    def get_corner_angles(self):\n",
    "        angles = {}\n",
    "        for e1, e2 in pairwise(list(self.edges.keys())):\n",
    "            # The corner will be duplicated by the edge names: tl_tr, tr_br => tr\n",
    "            vertice = Counter(e1.split('_') + e2.split('_')).most_common(1)[0][0]\n",
    "            angles[vertice] = calculate_angle_between_lines(self.edges[e1], self.edges[e2])  \n",
    "        return angles\n",
    "\n",
    "    def is_wellformed_label_shape(self):\n",
    "        \"\"\"\n",
    "        Validate the label shape, 4 corners & opposite angles be within 15 degrees\n",
    "        \"\"\"\n",
    "        valid_angle = 15\n",
    "        if len(self.vertices) != 4:\n",
    "            return False\n",
    "        oppos_corners = [('a', 'c'), ('b', 'd')]\n",
    "        max_angle_diff = max([abs(self.angles[i] - self.angles[j]) for i,j in oppos_corners])  \n",
    "        return max_angle_diff < valid_angle\n",
    "\n",
    "    def _visualise(self, image):\n",
    "        for edge in self.edges.values():\n",
    "            p = np.array(edge.coords).astype(np.int32)\n",
    "            cv2.line(image, p[0], p[1], (0, 255, 0), 30)\n",
    "        for point in self.vertices.values():\n",
    "            pt = np.array(point).astype(np.int32)\n",
    "            cv2.circle(image, pt, 5, (255,0,0), 50)\n",
    "        return image\n",
    "\n",
    "    @property\n",
    "    def x_length(self):\n",
    "        return round(max([self.edges['a_b'].length, self.edges['c_d'].length]))\n",
    "\n",
    "    @property\n",
    "    def y_length(self):\n",
    "        return round(max([self.edges['b_c'].length, self.edges['d_a'].length]))\n",
    "\n",
    "    def is_landscape(self):\n",
    "        return self.x_length > self.y_length\n",
    "\n",
    "    def get_normalised_label(self, image, max_longest_edge, max_shortest_edge):\n",
    "    \n",
    "        if self.is_landscape():\n",
    "            x = max_longest_edge\n",
    "            y = max_shortest_edge\n",
    "        else:\n",
    "            x = max_shortest_edge\n",
    "            y = max_longest_edge\n",
    "            \n",
    "        dest = np.float32([\n",
    "            (0, x), #A\n",
    "            (0, 0), #B\n",
    "            (y, 0), #C\n",
    "            (y, x) #D\n",
    "        ])\n",
    "        \n",
    "        src = np.float32(list(self.vertices.values()))\n",
    "        M = cv2.getPerspectiveTransform(src, dest)\n",
    "    \n",
    "        warped_image = cv2.warpPerspective(image, M,(y, x),flags=cv2.INTER_LINEAR) \n",
    "\n",
    "        # Longest edge should be the bottom\n",
    "        h, w = warped_image.shape[:2]\n",
    "        if h > w:\n",
    "            warped_image = imutils.rotate_bound(warped_image, -90)\n",
    "\n",
    "        return warped_image      \n",
    "            \n",
    "\n",
    "class LabelMask(Base):\n",
    "    def __init__(self, data: np.array, image):\n",
    "        super().__init__(image)\n",
    "        self._data = data\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        return self._data.shape[0]\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        return self._data.shape[1]  \n",
    "\n",
    "    @property\n",
    "    def y_midpoint(self):\n",
    "        \"\"\"\n",
    "        Vertical midpoint of a mask\n",
    "        \"\"\"        \n",
    "        return sum([min(np.where(self._data == True)[0]), max(np.where(self._data == True)[0])]) / 2 \n",
    "        \n",
    "    def get_contour(self, epsilon=5):\n",
    "        contours, _ = cv2.findContours(self._data.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contour = np.vstack(contours)\n",
    "        # Simplify contour - otherwise approx_best_fit_ngon takes many seconds\n",
    "        # Requires low epsilon < 10 otherwise approx vertices are out\n",
    "        if epsilon:\n",
    "            contour = cv2.approxPolyDP(contour, epsilon, True)        \n",
    "        return contour\n",
    "\n",
    "    def edges(self) -> np.array:\n",
    "        \"\"\"\n",
    "        Get edges of a mask\n",
    "        \"\"\"\n",
    "        # Diff will reduce width by 1, so prepend with extra column of 0s\n",
    "        return np.diff(self._data, prepend=np.zeros(self.height)[0])  \n",
    "\n",
    "    def edge_points(self) -> List:   \n",
    "        \"\"\"\n",
    "        Get the edges \n",
    "        \"\"\"    \n",
    "        # Find the indices of True values in the mask, and return row col (points)\n",
    "        return [(col, row) for row, col in np.argwhere(self.edges())]  \n",
    "\n",
    "    def to_quadrilateral_roi(self):\n",
    "        \"\"\"\n",
    "        Get quadrilateral ROI around mask\n",
    "        \"\"\"\n",
    "        contour = self.get_contour()\n",
    "        vertices = approx_best_fit_ngon(contour)\n",
    "        quad_roi = QuadrilateralROI(vertices, self.image)\n",
    "\n",
    "        print('HERE')\n",
    "        self.log()\n",
    "        \n",
    "        # Move this outside - where we know the general shape from other labels\n",
    "        if quad_roi.is_wellformed_label_shape():        \n",
    "            return quad_roi\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        print('Guesstimating corners')\n",
    "\n",
    "        # TODO: Log\n",
    "        # We want to get the two edges intersection at point A (closest corner)\n",
    "        closest_edges = [quad_roi.edges[e] for e in ['a_b', 'd_a']]\n",
    "        vertices = approx_quadrilateral_from_closest_edges(closest_edges, self)\n",
    "\n",
    "        approx_quad_roi = QuadrilateralROI(vertices, self.image, is_approx=True)\n",
    "        if approx_quad_roi.is_wellformed_label_shape(): \n",
    "            return approx_quad_roi  \n",
    "\n",
    "    def _visualise(self, image):\n",
    "        contour = self.get_contour()\n",
    "        image = cv2.drawContours(image, contour, -1, (255, 255, 0), 20)\n",
    "        vertices = approx_best_fit_ngon(contour)\n",
    "        quad_roi = QuadrilateralROI(vertices, self.image)\n",
    "        image = quad_roi.visualise(image)\n",
    "        cv2.circle(image, quad_roi.closest_point, 5, (0,0,255), 50)   \n",
    "        return image\n",
    "\n",
    "def improve_contrast(image, discard=2):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image:\n",
    "    :param discard:\n",
    "\n",
    "    \"\"\"\n",
    "    image = skimage.img_as_float(image)\n",
    "    out = np.zeros_like(image)\n",
    "\n",
    "    for c, channel in enumerate(image.transpose(2, 0, 1)):\n",
    "        low = np.percentile(channel.flatten(), discard)\n",
    "        high = np.percentile(channel.flatten(), 100 - discard)\n",
    "        out[..., c] = (np.clip(channel, low, high) - low) / (high - low)\n",
    "\n",
    "    return out\n",
    "\n",
    "class AngledView(Base):\n",
    "\n",
    "    \"\"\"\n",
    "    A view of the specimen \n",
    "    \"\"\"\n",
    "\n",
    "    min_mask_size = 1500\n",
    "    \n",
    "    def __init__(self, path: Path):\n",
    "        # FIXME: Reading image twice\n",
    "        image = cv2.imread(str(path))\n",
    "        image = resize_image(image)\n",
    "        super().__init__(image)\n",
    "        self.label_masks = self._get_label_masks_from_predictions()\n",
    "        self._clean_obscured_masks()\n",
    "\n",
    "    def _get_label_masks_from_predictions(self):\n",
    "        predicted_masks = self._get_predicted_masks()\n",
    "        label_masks = [LabelMask(m, self.image) for m in predicted_masks]\n",
    "        # Sort by mask y midpoint\n",
    "        label_masks.sort(key = attrgetter('y_midpoint'))\n",
    "        return label_masks\n",
    "\n",
    "    def _get_predicted_masks(self):\n",
    "        self.predictions = predict_masks(self.image)\n",
    "        predicted_masks = self.predictions.get('instances').to(\"cpu\").pred_masks.numpy()\n",
    "        predicted_masks = self.filter_small_masks(predicted_masks)      \n",
    "        return predicted_masks\n",
    "\n",
    "    # There are all on angledview\n",
    "    def get_higher_labels_mask(self, label_index):\n",
    "        # Get masks higher up the label stack (lower masks have index 0)\n",
    "        higher_masks = self.label_masks[label_index+1:]\n",
    "        combined_mask = np.zeros((self.height, self.width), dtype=np.uint8)\n",
    "        for mask in higher_masks:\n",
    "            cv2.fillPoly(combined_mask, [mask.get_polygon()], 255)    \n",
    "        return combined_mask\n",
    "    \n",
    "    def _clean_obscured_masks(self):\n",
    "        \"\"\"\n",
    "        Some detected areas are actually parts of masks higher in the stack\n",
    "        So filter out obscured areas\n",
    "        \"\"\"\n",
    "        for label_index, mask in enumerate(self.label_masks):\n",
    "            higher_labels_mask = self.get_higher_labels_mask(label_index)\n",
    "            mask.subtract_mask(higher_labels_mask)        \n",
    "\n",
    "    def filter_small_masks(self, label_masks: np.array):\n",
    "        return [m for m in label_masks if np.count_nonzero(m) > self.min_mask_size]\n",
    "\n",
    "    # def remove_overlaps(self, label_masks: np.array):\n",
    "    #     n_ = np.shape(label_masks)[0]\n",
    "    \n",
    "    #     overlaps = []\n",
    "    #     for i in range(n_):\n",
    "    #         msk1 = label_masks[i]\n",
    "    #         N1 = len(np.where(msk1 == True)[0])\n",
    "    #         for j in range(i + 1, n_):\n",
    "    #             msk2 = label_masks[j]\n",
    "    #             N2 = len(np.where(msk2 == True)[0])\n",
    "    #             N_overlap = len(np.where((msk1 == True) & (msk2 == True))[0])\n",
    "    #             print(N_overlap)\n",
    "    #             R1 = np.round(N_overlap / N1, 4)\n",
    "    #             R2 = np.round(N_overlap / N2, 4)\n",
    "    #             if (N_overlap != 0) and ((R1 > 0.15) or (R2 > 0.15)):\n",
    "    #                 overlaps.append([i, j, R1, R2, N_overlap])\n",
    "\n",
    "    #     print(overlaps)\n",
    "        \n",
    "    #     overlaps_sorted = deepcopy(overlaps)\n",
    "    #     overlaps_sorted = sorted(overlaps_sorted, key=lambda x: x[4], reverse=True)\n",
    "    \n",
    "    #     masks_new = deepcopy(label_masks)\n",
    "    \n",
    "    #     for o in overlaps_sorted:\n",
    "    #         msk1 = masks_new[o[0]]\n",
    "    #         msk2 = masks_new[o[1]]\n",
    "    #         N_overlap = len(np.where((msk1 == True) & (msk2 == True))[0])\n",
    "    #         R1 = np.round(N_overlap / len(np.where(msk1 == True)[0]), 4)\n",
    "    #         R2 = np.round(N_overlap / len(np.where(msk2 == True)[0]), 4)\n",
    "    \n",
    "    #         msk_to_exclude_ = [o[0], o[1]][np.argmax([R1, R2])]\n",
    "    #         msk_to_include_ = [o[0], o[1]][np.argmin([R1, R2])]\n",
    "    \n",
    "    #         new_mask = self.overlap_exclusion(msk_to_exclude_, msk_to_include_, masks_new)\n",
    "    \n",
    "    #         masks_new[msk_to_exclude_] = new_mask\n",
    "    \n",
    "    #     for i in range(n_):\n",
    "    #         msk_orig = label_masks[i]\n",
    "    #         msk_new = masks_new[i]\n",
    "    #         n1 = len(np.where(msk_orig == True)[0])\n",
    "    #         n2 = len(np.where(msk_new == True)[0])\n",
    "    #         r = n2 / n1\n",
    "    #         if r < 0.1:\n",
    "    #             masks_new[i] = np.full(np.shape(masks_new[i]), False)\n",
    "\n",
    "    #     return masks_new\n",
    "\n",
    "    # @staticmethod\n",
    "    # def overlap_exclusion(msk_to_exclude_, msk_to_include_, tst):\n",
    "    #     msk_to_exclude = tst[msk_to_exclude_]\n",
    "    #     msk_to_include = tst[msk_to_include_]\n",
    "    #     msk_to_exclude_edit = deepcopy(msk_to_exclude)\n",
    "    #     msk_to_exclude_edit[np.where(msk_to_include == True)] = False\n",
    "    #     return msk_to_exclude_edit\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_masks)\n",
    "\n",
    "    def _visualise(self, image):\n",
    "        v = Visualizer(image[:, :, ::-1],\n",
    "           metadata=None, \n",
    "           scale=0.7, \n",
    "           instance_mode=ColorMode.IMAGE_BW  # remove the colors of unsegmented pixels\n",
    "        )\n",
    "        v = v.draw_instance_predictions(self.predictions[\"instances\"].to(\"cpu\"))\n",
    "        image = v.get_image()[:, :, ::-1]    \n",
    "        return image\n",
    "\n",
    "class Specimen():\n",
    "    def __init__(self, paths: List[Path]):\n",
    "        views = [AngledView(p) for p in paths]\n",
    "        # We only want to use a view if it has the same number of labels as other views\n",
    "        # So calculate the modal of all labels, and then views with missing labels will be excluded\n",
    "        num_labels_mode = mode([len(view) for view in views])        \n",
    "        self.views = [view for view in views if len(view) == num_labels_mode.mode]\n",
    "        if len(self.views) != len(views):\n",
    "            logger.warning('Mismatched label count between views - %s views with %s labels will be used', len(self.views), num_labels_mode.mode)        \n",
    "\n",
    "    def __iter__(self):\n",
    "        for view in self.views:\n",
    "            yield view\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.views)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.views[i]\n",
    "\n",
    "    def get_labels(self, label_index):\n",
    "\n",
    "        # Normalise labels so they are all equal width and height - using the maximum width/height\n",
    "        # of the largest label\n",
    "        dimensions = np.array([\n",
    "            sorted([view.rois[label_index].x_length, view.rois[label_index].y_length]) for view in self.views\n",
    "        ])\n",
    "\n",
    "        max_shortest_edge = np.max(dimensions[:,0])\n",
    "        max_longest_edge = np.max(dimensions[:,1])    \n",
    "\n",
    "        labels = []\n",
    "        for view in self.views:\n",
    "            roi = view.rois[label_index]\n",
    "            labels.append(\n",
    "                roi.get_normalised_label(view.image, max_longest_edge, max_shortest_edge)\n",
    "            )\n",
    "\n",
    "        # FIXME: loop through and \n",
    "        # First two labels will be opposite way up to last two - rotate the last two 180 degrees\n",
    "        # FIXME: This doesn't check the orientation - but this should work either way\n",
    "        # labels = labels[:2] + [imutils.rotate_bound(label, 180) for label in labels[2:]]\n",
    "        return labels\n",
    "      \n",
    "\n",
    "# specimen = Specimen(paths)\n",
    "\n",
    "view = AngledView(paths[1])\n",
    "\n",
    "masks = view._get_predicted_masks()\n",
    "\n",
    "# img = view.visualise()\n",
    "# plt.imshow(img), plt.show()\n",
    "\n",
    "# for roi in view.rois:\n",
    "#     img = roi.visualise()\n",
    "#     plt.imshow(img), plt.show()\n",
    "\n",
    "#     closest_edges = [roi.edges[e] for e in ['a_b', 'd_a']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae36ed2-4aa9-4dcf-a0c5-c71997a475c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INVALID_LABEL_SHAPE = -1\n",
    "\n",
    "class LabelMask(Base):\n",
    "    def __init__(self, mask: np.array, image):\n",
    "        self.height, self.width = image.shape[:2]\n",
    "        super().__init__(image)\n",
    "        self.mask = mask.astype(np.uint8)\n",
    "\n",
    "    @property\n",
    "    def y_midpoint(self):\n",
    "        \"\"\"\n",
    "        Vertical midpoint of a mask\n",
    "        \"\"\"        \n",
    "        return sum([min(np.where(self.mask == True)[0]), max(np.where(self.mask == True)[0])]) / 2 \n",
    "\n",
    "    @property\n",
    "    def contour(self):\n",
    "        contours, _ = cv2.findContours(self.mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # If we have multiple contours, only use the largest one\n",
    "        sorted_countors = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        return sorted_countors[0]\n",
    "        \n",
    "    def get_polygon(self, epsilon=None):\n",
    "        \"\"\"\n",
    "        Get polygon around the mask\n",
    "\n",
    "        Note: otherwise approx_best_fit_ngon takes many seconds so requires \n",
    "        low epsilon < 10 otherwise approx vertices are out \n",
    "        epsilon=5 works well\n",
    "        \"\"\"\n",
    "        if not epsilon:\n",
    "            epsilon = 0.02 * cv2.arcLength(self.contour, True)\n",
    "            \n",
    "        return cv2.approxPolyDP(self.contour, epsilon, True)\n",
    "\n",
    "    def edges(self) -> np.array:\n",
    "        \"\"\"\n",
    "        Get edges of a mask\n",
    "        \"\"\"\n",
    "        # Diff will reduce width by 1, so prepend with extra column of 0s\n",
    "        return np.diff(self.mask, prepend=np.zeros(self.height)[0])  \n",
    "\n",
    "    def edge_points(self) -> List:   \n",
    "        \"\"\"\n",
    "        Get the edges \n",
    "        \"\"\"    \n",
    "        # Find the indices of True values in the mask, and return row col (points)\n",
    "        return [(col, row) for row, col in np.argwhere(self.edges())]  \n",
    "\n",
    "    def _visualise(self, image):\n",
    "        contour = self.contour\n",
    "        image = cv2.drawContours(image, contour, -1, (255, 255, 0), 20)\n",
    "        cv2.drawContours(image, [self.get_polygon()], -1, (0, 255, 0), 2)  # Draw in green        \n",
    "        return image\n",
    "\n",
    "    def subtract_mask(self, subtraction_mask):\n",
    "        \"\"\"\n",
    "        Subtract mask from mask\n",
    "        \"\"\"\n",
    "        self.mask = cv2.bitwise_and(self.mask, cv2.bitwise_not(subtraction_mask))        \n",
    "        \n",
    "\n",
    "label_masks = [LabelMask(mask, view.image) for mask in masks]\n",
    "image = view.image.copy()\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# There are all on angledview\n",
    "def get_higher_labels_mask(label_index):\n",
    "    # Get masks higher up the label stack (lower masks have index 0)\n",
    "    higher_masks = label_masks[label_index+1:]\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for mask in higher_masks:\n",
    "        cv2.fillPoly(combined_mask, [mask.get_polygon()], 255)\n",
    "\n",
    "    return combined_mask\n",
    "\n",
    "def remove_obscured_masks():\n",
    "    \"\"\"\n",
    "    Some detected areas are actually parts of masks higher in the stack\n",
    "    So filter out obscured areas\n",
    "    \"\"\"\n",
    "    for label_index, mask in enumerate(label_masks):\n",
    "        higher_labels_mask = get_higher_labels_mask(label_index)\n",
    "        mask.subtract_mask(higher_labels_mask)\n",
    "\n",
    "class Quadrilateral(Base):\n",
    "    def __init__(self, mask):\n",
    "        super().__init__(mask.image)\n",
    "        contour = mask.get_polygon(epsilon=5)\n",
    "        vertices = approx_best_fit_ngon(contour)\n",
    "        \n",
    "        # Closest point to the bottom of the canvas\n",
    "        self.closest_point = self.get_closest_point(vertices)\n",
    "\n",
    "        # Vertices are assigned to a,b,c,d\n",
    "        # A will be the closest point (with the maximum y value), with the points\n",
    "        # ordered counter clockwise, with b being the next corner counter clockwise\n",
    "        # A & C will be opposite each other; B & D opposite\n",
    "        self.vertices = OrderedDict(zip(['a', 'b', 'c', 'd'], iter_list_from_value(vertices, self.closest_point)))\n",
    "        \n",
    "        # Loop through vertices, creating edges names a_b, b_c etc.,\n",
    "        self.edges = OrderedDict([(\n",
    "            f'{k1}_{k2}', LineString([\n",
    "                self.vertices[k1], \n",
    "                self.vertices[k2]\n",
    "            ])) for k1, k2 in pairwise(list(self.vertices.keys()))\n",
    "        ])\n",
    "        self.angles = self.get_corner_angles()\n",
    "\n",
    "    def get_closest_point(self, vertices):\n",
    "        \"\"\"\n",
    "        Closest point is the bottom corner nearest the center point of the image\n",
    "        \"\"\"\n",
    "        center = round(self.image.shape[1] / 2)\n",
    "        vertices = np.array(vertices)\n",
    "        bottom_corners = vertices[np.argpartition(vertices[:, 1], -2)[-2:]]\n",
    "        x_offset_from_center = np.abs(bottom_corners[:, 0] - center)\n",
    "        closest_point = bottom_corners[np.argmin(x_offset_from_center)]\n",
    "        return tuple(closest_point)\n",
    "\n",
    "    def get_corner_angles(self):\n",
    "        angles = {}\n",
    "        maxv = len(self.vertices) - 1\n",
    "        for i, vertice in enumerate(self.vertices.keys()):    \n",
    "            next_vertice = vertice_labels[i+1 if i < maxv else 0]\n",
    "            prev_vertice = vertice_labels[i-1 if i > 0 else maxv]\n",
    "            vertices = np.array([\n",
    "                self.vertices[prev_vertice],\n",
    "                self.vertices[vertice],\n",
    "                self.vertices[next_vertice]\n",
    "            ])\n",
    "            angle = calculate_angle(*vertices.ravel())\n",
    "            angles[vertice] = angle        \n",
    "        return angles\n",
    "\n",
    "    def is_wellformed_label_shape(self):\n",
    "        \"\"\"\n",
    "        Validate the label shape, 4 corners & opposite angles be within 15 degrees\n",
    "        \"\"\"\n",
    "        valid_angle = 15\n",
    "        if len(self.vertices) != 4:\n",
    "            return False\n",
    "        oppos_corners = [('a', 'c'), ('b', 'd')]\n",
    "        max_angle_diff = max([abs(self.angles[i] - self.angles[j]) for i,j in oppos_corners])  \n",
    "        return max_angle_diff < valid_angle\n",
    "\n",
    "    def nearest_corner_is_good(self):\n",
    "        \"\"\"\n",
    "        See if the nearest corner has acceptable angle range\n",
    "        \"\"\"\n",
    "        lower_bound = 100\n",
    "        upper_bound = 130\n",
    "        return lower_bound <= self.angles['a'] <= upper_bound\n",
    "\n",
    "    @property\n",
    "    def x_length(self):\n",
    "        return round(max([self.edges['a_b'].length, self.edges['c_d'].length]))\n",
    "\n",
    "    @property\n",
    "    def y_length(self):\n",
    "        return round(max([self.edges['b_c'].length, self.edges['d_a'].length]))\n",
    "\n",
    "    def is_landscape(self):\n",
    "        return self.x_length > self.y_length\n",
    "\n",
    "    def _visualise(self, image):\n",
    "        for edge in self.edges.values():\n",
    "            p = np.array(edge.coords).astype(np.int32)\n",
    "            cv2.line(image, p[0], p[1], (0, 255, 0), 5)\n",
    "        for point in self.vertices.values():\n",
    "            pt = np.array(point).astype(np.int32)\n",
    "            cv2.circle(image, pt, 5, (255,0,0), 10)\n",
    "\n",
    "        pt = np.array(self.closest_point).astype(np.int32)\n",
    "        cv2.circle(image, pt, 5, (255,0,255), 12)            \n",
    "        return image  \n",
    "\n",
    "\n",
    "\n",
    "# for label_mask in label_masks:\n",
    "\n",
    "view = AngledView(paths[0])\n",
    "masks = view._get_predicted_masks()\n",
    "\n",
    "label_masks = [LabelMask(mask, view.image) for mask in masks]\n",
    "image = view.image.copy()\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "remove_obscured_masks()\n",
    "\n",
    "label_mask = label_masks[0]\n",
    "quad = Quadrilateral(label_mask)\n",
    "\n",
    "img = quad.visualise()\n",
    "plt.imshow(img), plt.show()\n",
    "\n",
    "print(quad.angles)\n",
    "\n",
    "print(quad.is_wellformed_label_shape())\n",
    "\n",
    "print(quad.nearest_corner_is_good())\n",
    "\n",
    "\n",
    "# img = label_mask.visualise()\n",
    "# plt.imshow(img), plt.show()\n",
    "\n",
    "# image = view.image.copy()\n",
    "# mask = masks[0]\n",
    "# mask1 = masks[1]\n",
    "\n",
    "\n",
    "# contours, _ = cv2.findContours(mask1.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "# # for contour in contours:\n",
    "# contours_sorted_by_area = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "# image = cv2.drawContours(image, contours_sorted_by_area[0], -1, (255, 255, 0), 20)\n",
    "\n",
    "# largest_contour = contours_sorted_by_area[0]\n",
    "\n",
    "\n",
    "# cv2.drawContours(image, [approx_polygon], -1, (0, 255, 0), 2)  # Draw in green\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1936af2-76e6-4134-8504-4872ca476760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image = quad.image.copy()\n",
    "\n",
    "a = quad.vertices['b']\n",
    "pt = np.array(a).astype(np.int32)\n",
    "cv2.circle(image, pt, 5, (255,0,255), 12)   \n",
    "\n",
    "a = quad.vertices['b']\n",
    "pt = np.array(a).astype(np.int32)\n",
    "cv2.circle(image, pt, 5, (255,0,255), 12) \n",
    "\n",
    "print(quad.edges)\n",
    "\n",
    "e1 = quad.edges['d_a']\n",
    "e2 = quad.edges['c_d']\n",
    "\n",
    "\n",
    "pts1 = np.array(e1.coords).astype(np.int32)\n",
    "x1,y1 = pts1\n",
    "cv2.line(image, x1, y1, (0, 255, 0), 5)\n",
    "\n",
    "pts2 = np.array(e2.coords).astype(np.int32)\n",
    "x2, y2 = pts2\n",
    "cv2.line(image, x2, y2, (0, 255, 0), 5)\n",
    "\n",
    "plt.imshow(image), plt.show()\n",
    "\n",
    "combined_array = np.concatenate((pts1, pts2))\n",
    "unique_array = np.unique(combined_array, axis=0)\n",
    "print(unique_array)\n",
    "print(quad.vertices['a'])\n",
    "print(quad.vertices['d'])\n",
    "print(quad.vertices['c'])\n",
    "\n",
    "\n",
    "unique_array = np.array([\n",
    "    quad.vertices['d'],\n",
    "    quad.vertices['a'],\n",
    "    quad.vertices['b']\n",
    "])\n",
    "\n",
    "print(calculate_angle(*unique_array.ravel()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# angles = {}\n",
    "# for e1, e2 in pairwise(list(quad.edges.keys())):\n",
    "#     # The corner will be duplicated by the edge names: tl_tr, tr_br => tr\n",
    "#     vertice = Counter(e1.split('_') + e2.split('_')).most_common(1)[0][0]\n",
    "    \n",
    "#     edge1_points = np.array(quad.edges[e1].coords).astype(np.int32)\n",
    "#     edge2_points = np.array(quad.edges[e2].coords).astype(np.int32)\n",
    "    \n",
    "#     points = np.concatenate((edge1_points, edge2_points))\n",
    "#     three_points = np.unique(points, axis=0)\n",
    "#     angles[vertice] = calculate_angle(*three_points.ravel()) \n",
    "\n",
    "# print(angles)        \n",
    "\n",
    "# print(ab_points)\n",
    "# print(da_points)\n",
    "# combined_array = np.concatenate((ab_points, da_points))\n",
    "\n",
    "# # Remove duplicates by getting the unique elements\n",
    "# unique_array = np.unique(combined_array, axis=0)\n",
    "\n",
    "# print(unique_array.ravel())\n",
    "\n",
    "# # sorted_indices = np.argsort(unique_array[:, 1])\n",
    "\n",
    "# # # Apply the sorted indices to the original array\n",
    "# # unique_array = unique_array[sorted_indices]\n",
    "\n",
    "    \n",
    "# # # Calculate the angles at each corner\n",
    "angle_A = calculate_angle(*unique_array.ravel())\n",
    "\n",
    "# print(angle_A)\n",
    "\n",
    "3\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864a743-c092-4813-bd00-6697e49a9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertice_labels = \n",
    "\n",
    "\n",
    "print(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d64cf-0e2b-4df4-b5ca-9239c80cfc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4]\n",
    "\n",
    "x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba3458-7467-44ec-9345-91640c8f17f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0183444e-7452-4fe5-808f-3ece4b249837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for view in specimen.views:\n",
    "# #     vis = view.visualise()\n",
    "# #     plt.imshow(vis), plt.show()\n",
    "\n",
    "# import skimage\n",
    "\n",
    "label_index = 1\n",
    "\n",
    "# # def get_label_rois(label_index):  \n",
    "# #     return [view.rois[label_index] for view in specimen.views]\n",
    "\n",
    "# # for label in specimen.get_labels(label_index):\n",
    "# #     plt.imshow(label), plt.show()\n",
    "\n",
    "# for view in specimen:\n",
    "#     for roi in view.rois:\n",
    "#         vis = roi.get_perspective_transformed(view.image)\n",
    "#         plt.imshow(vis), plt.show()\n",
    "#         break\n",
    "        \n",
    "    \n",
    "\n",
    "labels = specimen.get_labels(label_index)\n",
    "\n",
    "labels = labels[:2] + [imutils.rotate_bound(label, 180) for label in labels[2:]]\n",
    "\n",
    "for view in specimen:\n",
    "    for roi in view.rois:\n",
    "        img = roi.visualise(view.image)\n",
    "        plt.imshow(img), plt.show()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.imshow(label), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0f113-eb71-49e7-8538-f3a80f4cfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for view in specimen:\n",
    "#     vis = view.image\n",
    "#     plt.imshow(vis), plt.show()\n",
    "    \n",
    "#     # for roi in view.rois:\n",
    "#     #     vis = roi.visualise(view.image)\n",
    "#     #     plt.imshow(vis), plt.show()\n",
    "\n",
    "# labels[0]\n",
    "\n",
    "\n",
    "l = cv2.imread('label0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ed9a8-549c-4523-82ab-6544388cf265",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = craft.detect(l)\n",
    "prediction2 = craft.detect(labels[0])\n",
    "\n",
    "import skimage\n",
    "def improve_contrast(image, discard=2):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image:\n",
    "    :param discard:\n",
    "\n",
    "    \"\"\"\n",
    "    image = skimage.img_as_float(image)\n",
    "    out = np.zeros_like(image)\n",
    "\n",
    "    for c, channel in enumerate(image.transpose(2, 0, 1)):\n",
    "        low = np.percentile(channel.flatten(), discard)\n",
    "        high = np.percentile(channel.flatten(), 100 - discard)\n",
    "        out[..., c] = (np.clip(channel, low, high) - low) / (high - low)\n",
    "\n",
    "    return out\n",
    "\n",
    "prediction3 = craft.detect(labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d08c0-c234-4053-9147-7ca35cccf5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    plt.imshow(label), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fdcbc8-318b-4946-87ff-19643a7d821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction1 = craft.detect(labels[2])\n",
    "# plt.imshow(prediction1['resized_heatmap']), plt.show()\n",
    "# plt.imshow(prediction1['image']), plt.show()\n",
    "\n",
    "# plt.imshow(prediction2['resized_heatmap']), plt.show()\n",
    "# plt.imshow(prediction2['image']), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755d792-a892-4748-ace2-4f7fa6bb09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(prediction1['image']), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066eadd-5ce8-4e55-9906-7f0cc05664c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def rectangle_get_vertices(rect):\n",
    "#     top_left, bottom_right = rect    \n",
    "#     top_right = np.array([bottom_right[0], top_left[1]])\n",
    "#     bottom_left = np.array([top_left[0], bottom_right[1]])   \n",
    "#     return np.array([top_left, top_right, bottom_right, bottom_left])\n",
    "\n",
    "class TextLine():\n",
    "    def __init__(self, rect, image, baseline_centroids):\n",
    "        self.rect = rect\n",
    "        x1, y1, x2, y2 = rect.ravel()\n",
    "        self.orig_image = image[y1:y2, x1:x2]\n",
    "        self.height, self.width = self.orig_image.shape[:2]\n",
    "        # Baselines are calculate to the whole image - adjust\n",
    "        baseline_centroids[:, 1] -= y1\n",
    "        self.baseline_centroids = baseline_centroids\n",
    "        self.image = self.deskew()\n",
    "             \n",
    "    def get_line_best_fit(self):\n",
    "        # Fit a polynomial of degree 2 (quadratic)\n",
    "        degree = 2      \n",
    "        x, y = self.baseline_centroids.T\n",
    "        coefficients = np.polyfit(x, y, degree) \n",
    "        return np.poly1d(coefficients)\n",
    "\n",
    "    def deskew(self):\n",
    "        poly = self.get_line_best_fit()\n",
    "        x = np.linspace(0, self.width-1, self.width)        \n",
    "        y_hat = poly(x)   \n",
    "        # Offset is the predicted y values minus the maximum  \n",
    "        y_offsets = max(y_hat) - y_hat\n",
    "        deskewed = self.orig_image.copy()\n",
    "        channels = deskewed.shape[2]\n",
    "        # Roll down pixels by the offset from the line of best fit\n",
    "        for i, y_offset in enumerate(y_offsets):\n",
    "            y = round(y_offset)\n",
    "            for c in range(channels):\n",
    "                deskewed[:, i, c] = np.roll(deskewed[:, i, c], y)\n",
    "            deskewed[:y, i, :] = 255\n",
    "        return deskewed\n",
    "\n",
    "    def visualise(self):\n",
    "        image = self.orig_image.copy()\n",
    "        poly = self.get_line_best_fit()\n",
    "        xs = np.linspace(0, self.width -1, self.width)\n",
    "        y_hat = poly(xs)\n",
    "        for x, y in zip(xs.astype(int),y_hat.astype(int)):\n",
    "            image[y, x] = [255, 0, 0]            \n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "class Label():\n",
    "\n",
    "    craft = Craft()\n",
    "\n",
    "    # def __init__(image):\n",
    "    #     prediction = self.craft.detect(image)\n",
    "    #     self.text_lines = self.get_text_lines(prediction)\n",
    "    \n",
    "    def __init__(self, prediction):\n",
    "        self.image = prediction['image']\n",
    "        self.heatmap = prediction['resized_heatmap']        \n",
    "        self.height, self.width = self.image.shape[:2]\n",
    "        # self.lines = self._get_text_lines()\n",
    "    \n",
    "    def _get_text_lines(self):\n",
    "        padding = 3\n",
    "        rects = []\n",
    "        clusters = self._get_clustered_rectangles()\n",
    "        for cluster in clusters.values():\n",
    "            ymin, ymax = minmax(cluster[:,:,1])\n",
    "            # Adjust ymin / ymax by buffer\n",
    "            ymin -= padding if ymin - padding > 0 else 0\n",
    "            ymax += padding if ymax + padding < self.height else self.height\n",
    "            # Line rectangle vertices\n",
    "            line_rect = np.array([\n",
    "                (0, ymin), \n",
    "                (self.width, ymax),\n",
    "            ])\n",
    "            # Calculate the baseline centroids of the heatmap (letter) rectangles\n",
    "            baseline_centroids = np.array([\n",
    "                (np.mean(rect[:, 0], dtype=np.int32), max(rect[:, 1])) for rect in cluster\n",
    "            ]) \n",
    "            rects.append(TextLine(line_rect, self.image, baseline_centroids))\n",
    "            \n",
    "        return rects\n",
    "\n",
    "    @staticmethod\n",
    "    def _filter_outliers(rects):\n",
    "        \"\"\"\n",
    "        Filter any outlier rects by height (joined up letters)\n",
    "        \"\"\"\n",
    "        threshold = 3\n",
    "        rects = np.array(rects)\n",
    "        rectangle_heights = np.abs(np.diff(rects[:,:,1]))\n",
    "        z_scores = np.abs(zscore(rectangle_heights))\n",
    "        return rects[np.where(z_scores < threshold)[0]]        \n",
    "\n",
    "    def _get_heatmap_rectangles(self):\n",
    "        \"\"\"\n",
    "        Draw rectangles around points of heatmap density (representing letters)   \n",
    "        \"\"\"\n",
    "        # Define the threshold value - values above this will be hotspots to draw boxes around\n",
    "        b, g, r = cv2.split(self.heatmap)\n",
    "        # threshold = 200    \n",
    "        \n",
    "        height = self.heatmap.shape[0]\n",
    "        # heatmap = np.array(cv2.cvtColor(self.heatmap, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "        # # Create a binary mask\n",
    "        # binary_mask = heatmap > threshold    \n",
    "\n",
    "\n",
    "        b, g, r = cv2.split(self.heatmap)\n",
    "        threshold = 120\n",
    "        binary_mask = b < threshold  \n",
    "        \n",
    "        # Find contours in the binary mask\n",
    "        contours, _ = cv2.findContours(binary_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "        rects = []        \n",
    "    \n",
    "        # Filter out smaller contours\n",
    "        min_area = 4\n",
    "        contours = [contour for contour in contours if cv2.contourArea(contour) >= min_area]\n",
    "        \n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # Remove any boxes along the top/bottom edges - overlapping from other rows\n",
    "            if y == 0 or (y + h) >= height: continue            \n",
    "            rects.append([(x, y), (x + w, y + h)])   \n",
    "            \n",
    "        return np.array(rects) \n",
    "    \n",
    "    def _get_clustered_rectangles(self):\n",
    "        heatmap_rects = self._get_heatmap_rectangles()\n",
    "        baselines = np.array([max(y) for y in heatmap_rects[:,:, 1]])\n",
    "        thresh = 30\n",
    "        # cluster_labels = hcluster.fclusterdata(baselines.reshape(-1,1), thresh, criterion=\"distance\")\n",
    "        cluster_labels = hcluster.fclusterdata(baselines.reshape(-1,1), t=3, criterion=\"maxclust\")\n",
    "        print(cluster_labels)\n",
    "        clusters = {}\n",
    "        for label, rect in zip(cluster_labels, heatmap_rects):\n",
    "            clusters.setdefault(label, []).append(rect)\n",
    "\n",
    "        return {label: self._filter_outliers(cluster) for label, cluster in clusters.items()}        \n",
    "        \n",
    "    def visualise(self):\n",
    "\n",
    "        image = self.image.copy()\n",
    "        clusters = self._get_clustered_rectangles()\n",
    "\n",
    "        for label, cluster in clusters.items():\n",
    "            color = random_colour()\n",
    "            for rect in cluster:\n",
    "                pt1, pt2 = rect\n",
    "                cv2.rectangle(image, pt1, pt2, color, -1)\n",
    "\n",
    "        # for text_line in self._get_text_lines():\n",
    "        #     color = random_colour()\n",
    "        #     pt1, pt2 = text_line.rect\n",
    "        #     cv2.rectangle(image, pt1, pt2, color, 1)                \n",
    "        return image\n",
    "        \n",
    "        \n",
    "label = Label(prediction1)\n",
    "\n",
    "# for line in label.lines:\n",
    "#     vis = line.visualise()\n",
    "#     plt.imshow(vis, 'gray')\n",
    "#     plt.show()\n",
    "#     plt.imshow(line.image, 'gray')\n",
    "#     plt.show()    \n",
    "# # for line in label.text_lines:\n",
    "# #     print(line)\n",
    "\n",
    "image = label.visualise()\n",
    "plt.imshow(image, 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03b8ca-a43b-4d2b-9b14-ecaed99dd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = prediction2['resized_heatmap']\n",
    "b, g, r = cv2.split(heatmap)\n",
    "plt.imshow(heatmap), plt.show()\n",
    "\n",
    "# Convert BGR image to HSV\n",
    "hsv_image = cv2.cvtColor(heatmap, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the blue hue range\n",
    "lower_blue = np.array([120, 50, 50])\n",
    "upper_blue = np.array([150, 255, 255])\n",
    "\n",
    "# lower_blue = np.array([60, 50, 50])  # Lower hue value increased\n",
    "# upper_blue = np.array([0, 255, 255])  # Upper hue value decreased\n",
    "\n",
    "# Create a mask for blue elements\n",
    "\n",
    "threshold = 40\n",
    "binary_mask = b < threshold  \n",
    "\n",
    "# blue_mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "plt.imshow(binary_mask), plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71db57-15e4-4c56-bc9f-380487186054",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # heatmap = np.array(cv2.cvtColor(b, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "print(b)\n",
    "\n",
    "# # Create a binary mask\n",
    "# binary_mask = b > threshold    \n",
    "# # Find contours in the binary mask\n",
    "# contours, _ = cv2.findContours(binary_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "# rects = []        \n",
    "\n",
    "# # Filter out smaller contours\n",
    "# min_area = 4\n",
    "# contours = [contour for contour in contours if cv2.contourArea(contour) >= min_area]\n",
    "\n",
    "# for contour in contours:\n",
    "#     x, y, w, h = cv2.boundingRect(contour)\n",
    "#     # Remove any boxes along the top/bottom edges - overlapping from other rows\n",
    "#     if y == 0 or (y + h) >= height: continue            \n",
    "#     rects.append([(x, y), (x + w, y + h)])   \n",
    "        \n",
    "#     # return np.array(rects) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36044448-82c6-45ee-bdda-0e2431cfc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "paths = [PROCESSING_INPUT_DIR / f'011250151_additional({i}).JPG' for i in range(1,5)]\n",
    "\n",
    "path = paths[0]\n",
    "image = cv2.imread(str(path))\n",
    "\n",
    "x = resize_image(image)\n",
    "plt.imshow(x), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd347aa-d46c-40f8-b7fd-6ee67108d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([(0, 10), (50, 15), (55, 400), (10, 390)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04093a97-e216-4280-a527-b51b8a500e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_value = 396\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd546c1-d451-4f7a-96a0-1d29cc0a9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2081b-c248-4d53-ba1f-4d4d50785165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efdd33-ece3-4155-8e28-bfaa7bc22895",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '011244568_additional_4'\n",
    "re_filename = re.compile(r'additional_?\\(?(?P<image_id>[1-4])\\)$')\n",
    "\n",
    "re_filename.search(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474efd48-c47e-406d-84c9-3626394a983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.group('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed3ec2-5951-4d46-87c9-359eadd7dba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac292fa-4fe2-4f7f-8da6-26b201f89951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRAFT-pytorch",
   "language": "python",
   "name": "craft-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
