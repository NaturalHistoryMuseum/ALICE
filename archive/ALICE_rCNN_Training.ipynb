{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQJ/9xpcI8XQ362ZDQVf/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LittleAri/ALICE/blob/main/ALICE_rCNN_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask RCNN Training for ALICE\n",
        "\n",
        "Train model ([Mask RCNN](https://github.com/matterport/Mask_RCNN)) on images of pinned insects."
      ],
      "metadata": {
        "id": "YeuepQudH8H7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 0\n",
        "Mount Google Drive.\n",
        "\n",
        "This step is useful if using Google Colab, as it's often easier to save documents there."
      ],
      "metadata": {
        "id": "8G3w5PHWCPzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c1P7lEJCUdI",
        "outputId": "0e21c0c1-de52-4b18-f463-669a96efc10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1\n",
        "\n",
        "Check that images have loaded properly.\n",
        "\n",
        "This is a precautionary step which is helpful when using Google Colab, to check if images have been uploaded correctly."
      ],
      "metadata": {
        "id": "9JP0iQWmh1i5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTaLNu8qfkTv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import skimage.io as io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = 0\n",
        "non_errors = 0\n",
        "\n",
        "for nm in os.listdir(\"balloon/val\"):\n",
        "  if \"json\" not in nm:\n",
        "    try:\n",
        "      image = io.imread(\"balloon/val/\"+nm)\n",
        "      non_errors = non_errors+1\n",
        "    except:\n",
        "      print(nm)\n",
        "      errors = errors+1\n",
        "\n",
        "print([\"val\",non_errors,errors])"
      ],
      "metadata": {
        "id": "criJLe5mgxRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5887a1-3427-4b0f-f4b4-634729dfca49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['val', 15, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2\n",
        "\n",
        "Import certain versions of Python packages."
      ],
      "metadata": {
        "id": "9ylGCol8h7rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.15.5\n",
        "!pip install keras==2.1.0\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install numpy==1.21.5\n",
        "!pip install tensorflow-gpu==1.15.5\n",
        "!pip install scikit-image==0.16.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eztjdoJ6h7Nw",
        "outputId": "531ff773-c187-410b-a9ad-c62b1a7b4981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.0.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 30.1 MB/s \n",
            "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.44.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Collecting h5py<=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 32.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.10.0.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=9d8bc273c6988a7f141b5e8a8c874f33062fce44916f00cd25487faed98f7594\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: numpy, h5py, tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.1.0\n",
            "  Downloading Keras-2.1.0-py2.py3-none-any.whl (302 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 302 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.1.0\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-3nxi5owm\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-3nxi5owm\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101077 sha256=111b795b52b6900f68392e7bee26e716ec37f16d5befeb996831c8e6f0a0fcda\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3s_8ls8s/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 1.15.5 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==1.15.5\n",
            "  Downloading tensorflow_gpu-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.0.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.0.8)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Using cached numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (3.7.0)\n",
            "Installing collected packages: numpy, tensorflow-gpu\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.18.5 tensorflow-gpu-1.15.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-image==0.16.2\n",
            "  Downloading scikit_image-0.16.2-cp37-cp37m-manylinux1_x86_64.whl (26.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.5 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image==0.16.2) (1.18.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.15.0)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-image-0.16.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "skimage"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3:\n",
        "Import libraries."
      ],
      "metadata": {
        "id": "Hf3AJmqNrJN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import utils\n",
        "import visualize\n",
        "from visualize import display_images\n",
        "import balloon\n",
        "from model import log\n",
        "import skimage\n",
        "from google.colab import files as files_\n",
        "import os\n",
        "import tensorflow as tf\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "7n3eSD54g4TX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff202786-1ab2-4c44-9f31-b0b6841d77c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4\n",
        "\n",
        "Double check if there's a GPU."
      ],
      "metadata": {
        "id": "irrkMIZArcZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFI-DWSfrRcG",
        "outputId": "14aad3bd-3b47-4a17-c183-3e83275d403f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5\n",
        "\n",
        "Train model by building on top of pre-trained weights.\n",
        "\n",
        "The path for the images / labels that will be used for trianing, should be specified in _folder_for_labels_. The path to the folder containing the model and the pre-trained weights should be specified in _folder_for_model_."
      ],
      "metadata": {
        "id": "5kyL68Tvrh-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_for_labels = balloon\n",
        "folder_for_model = coco\n",
        "\n",
        "!python3 balloon.py train --dataset=folder_for_labels --weights=folder_for_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WsvpdlWrftZ",
        "outputId": "ff88430d-0a8e-4708-b950-0dc50bec2afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "Weights:  coco\n",
            "Dataset:  balloon\n",
            "Logs:  /logs\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           label\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                50\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "ERROR WITH DOWNLOADING WEIGHTS\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/model.py:626: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/model.py:674: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "Downloading pretrained model to /mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n",
            "Loading weights  /mask_rcnn_coco.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:158: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:163: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-03-31 13:51:23.831703: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-03-31 13:51:23.837148: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2022-03-31 13:51:23.837381: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564adf17b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-31 13:51:23.837430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-03-31 13:51:23.839449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-31 13:51:23.962830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-31 13:51:23.963785: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564adf17b800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-31 13:51:23.963822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2022-03-31 13:51:23.964045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-31 13:51:23.965102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-03-31 13:51:23.965500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-03-31 13:51:23.966988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-03-31 13:51:23.968342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-03-31 13:51:23.968757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-03-31 13:51:23.977354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-03-31 13:51:23.978659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-03-31 13:51:23.983809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-03-31 13:51:23.983983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-31 13:51:23.984941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-31 13:51:23.985670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-03-31 13:51:23.985754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-03-31 13:51:23.987402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-03-31 13:51:23.987440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-03-31 13:51:23.987458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-03-31 13:51:23.987614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-31 13:51:23.988433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-31 13:51:23.989204: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-03-31 13:51:23.989262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:172: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:188: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "ERROR WITH DOWNLOADING WEIGHTS\n",
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /logs/label20220331T1351/mask_rcnn_label_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:940: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2039: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "Epoch 1/25\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b3ed52000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "2022-03-31 13:52:37.198624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-03-31 13:52:38.016122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b2d068000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "49/50 [============================>.] - ETA: 3s - loss: 2.2123 - rpn_class_loss: 0.0885 - rpn_bbox_loss: 0.5448 - mrcnn_class_loss: 0.1203 - mrcnn_bbox_loss: 0.6508 - mrcnn_mask_loss: 0.8080/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2197: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b6f09c000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b70c94000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:791: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "50/50 [==============================] - 513s 10s/step - loss: 2.2149 - rpn_class_loss: 0.0875 - rpn_bbox_loss: 0.5557 - mrcnn_class_loss: 0.1222 - mrcnn_bbox_loss: 0.6480 - mrcnn_mask_loss: 0.8015 - val_loss: 1.4038 - val_rpn_class_loss: 0.0396 - val_rpn_bbox_loss: 0.5453 - val_mrcnn_class_loss: 0.1220 - val_mrcnn_bbox_loss: 0.3577 - val_mrcnn_mask_loss: 0.3393\n",
            "Epoch 2/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 1.0147 - rpn_class_loss: 0.0310 - rpn_bbox_loss: 0.2975 - mrcnn_class_loss: 0.0857 - mrcnn_bbox_loss: 0.3115 - mrcnn_mask_loss: 0.2890tcmalloc: large alloc 1207705600 bytes == 0x564b770d4000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b77092000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 375s 8s/step - loss: 1.0101 - rpn_class_loss: 0.0305 - rpn_bbox_loss: 0.2944 - mrcnn_class_loss: 0.0858 - mrcnn_bbox_loss: 0.3115 - mrcnn_mask_loss: 0.2879 - val_loss: 1.9094 - val_rpn_class_loss: 0.0707 - val_rpn_bbox_loss: 1.0994 - val_mrcnn_class_loss: 0.1027 - val_mrcnn_bbox_loss: 0.3793 - val_mrcnn_mask_loss: 0.2573\n",
            "Epoch 3/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.8722 - rpn_class_loss: 0.0187 - rpn_bbox_loss: 0.2481 - mrcnn_class_loss: 0.0937 - mrcnn_bbox_loss: 0.2585 - mrcnn_mask_loss: 0.2532tcmalloc: large alloc 1207705600 bytes == 0x564b71dcc000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b6208c000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 375s 8s/step - loss: 0.8647 - rpn_class_loss: 0.0184 - rpn_bbox_loss: 0.2460 - mrcnn_class_loss: 0.0928 - mrcnn_bbox_loss: 0.2566 - mrcnn_mask_loss: 0.2509 - val_loss: 2.1017 - val_rpn_class_loss: 0.0715 - val_rpn_bbox_loss: 1.4112 - val_mrcnn_class_loss: 0.0786 - val_mrcnn_bbox_loss: 0.3033 - val_mrcnn_mask_loss: 0.2372\n",
            "Epoch 4/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.7737 - rpn_class_loss: 0.0127 - rpn_bbox_loss: 0.2371 - mrcnn_class_loss: 0.0804 - mrcnn_bbox_loss: 0.2174 - mrcnn_mask_loss: 0.2261tcmalloc: large alloc 1207705600 bytes == 0x564b53de4000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b755ce000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 365s 7s/step - loss: 0.7680 - rpn_class_loss: 0.0126 - rpn_bbox_loss: 0.2353 - mrcnn_class_loss: 0.0792 - mrcnn_bbox_loss: 0.2149 - mrcnn_mask_loss: 0.2259 - val_loss: 1.7751 - val_rpn_class_loss: 0.0633 - val_rpn_bbox_loss: 1.1321 - val_mrcnn_class_loss: 0.0803 - val_mrcnn_bbox_loss: 0.2688 - val_mrcnn_mask_loss: 0.2306\n",
            "Epoch 5/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.6934 - rpn_class_loss: 0.0147 - rpn_bbox_loss: 0.2553 - mrcnn_class_loss: 0.0589 - mrcnn_bbox_loss: 0.1650 - mrcnn_mask_loss: 0.1995tcmalloc: large alloc 1207705600 bytes == 0x564b738b6000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b77068000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 363s 7s/step - loss: 0.6868 - rpn_class_loss: 0.0144 - rpn_bbox_loss: 0.2516 - mrcnn_class_loss: 0.0582 - mrcnn_bbox_loss: 0.1641 - mrcnn_mask_loss: 0.1984 - val_loss: 1.9414 - val_rpn_class_loss: 0.0635 - val_rpn_bbox_loss: 1.3219 - val_mrcnn_class_loss: 0.0611 - val_mrcnn_bbox_loss: 0.2711 - val_mrcnn_mask_loss: 0.2238\n",
            "Epoch 6/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.5798 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.1877 - mrcnn_class_loss: 0.0503 - mrcnn_bbox_loss: 0.1413 - mrcnn_mask_loss: 0.1901tcmalloc: large alloc 1207705600 bytes == 0x564b5e880000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b7386e000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 368s 7s/step - loss: 0.5785 - rpn_class_loss: 0.0103 - rpn_bbox_loss: 0.1862 - mrcnn_class_loss: 0.0502 - mrcnn_bbox_loss: 0.1414 - mrcnn_mask_loss: 0.1904 - val_loss: 1.7944 - val_rpn_class_loss: 0.0522 - val_rpn_bbox_loss: 1.1285 - val_mrcnn_class_loss: 0.1108 - val_mrcnn_bbox_loss: 0.2810 - val_mrcnn_mask_loss: 0.2218\n",
            "Epoch 7/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.5547 - rpn_class_loss: 0.0081 - rpn_bbox_loss: 0.1614 - mrcnn_class_loss: 0.0512 - mrcnn_bbox_loss: 0.1367 - mrcnn_mask_loss: 0.1973tcmalloc: large alloc 1207705600 bytes == 0x564b53de4000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b7386e000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 367s 7s/step - loss: 0.5526 - rpn_class_loss: 0.0079 - rpn_bbox_loss: 0.1604 - mrcnn_class_loss: 0.0509 - mrcnn_bbox_loss: 0.1364 - mrcnn_mask_loss: 0.1969 - val_loss: 1.8932 - val_rpn_class_loss: 0.0586 - val_rpn_bbox_loss: 1.2516 - val_mrcnn_class_loss: 0.1005 - val_mrcnn_bbox_loss: 0.2621 - val_mrcnn_mask_loss: 0.2203\n",
            "Epoch 8/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.4636 - rpn_class_loss: 0.0082 - rpn_bbox_loss: 0.1356 - mrcnn_class_loss: 0.0378 - mrcnn_bbox_loss: 0.1092 - mrcnn_mask_loss: 0.1728tcmalloc: large alloc 1207705600 bytes == 0x564b71dba000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b71e48000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 374s 7s/step - loss: 0.4736 - rpn_class_loss: 0.0087 - rpn_bbox_loss: 0.1436 - mrcnn_class_loss: 0.0389 - mrcnn_bbox_loss: 0.1098 - mrcnn_mask_loss: 0.1726 - val_loss: 2.2439 - val_rpn_class_loss: 0.0831 - val_rpn_bbox_loss: 1.6201 - val_mrcnn_class_loss: 0.0667 - val_mrcnn_bbox_loss: 0.2603 - val_mrcnn_mask_loss: 0.2137\n",
            "Epoch 9/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.4831 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.1522 - mrcnn_class_loss: 0.0361 - mrcnn_bbox_loss: 0.1166 - mrcnn_mask_loss: 0.1705tcmalloc: large alloc 1207705600 bytes == 0x564b75662000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b755b0000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 362s 7s/step - loss: 0.4784 - rpn_class_loss: 0.0075 - rpn_bbox_loss: 0.1500 - mrcnn_class_loss: 0.0356 - mrcnn_bbox_loss: 0.1156 - mrcnn_mask_loss: 0.1697 - val_loss: 2.1635 - val_rpn_class_loss: 0.0775 - val_rpn_bbox_loss: 1.5546 - val_mrcnn_class_loss: 0.0563 - val_mrcnn_bbox_loss: 0.2686 - val_mrcnn_mask_loss: 0.2064\n",
            "Epoch 10/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.4258 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.1107 - mrcnn_class_loss: 0.0402 - mrcnn_bbox_loss: 0.1005 - mrcnn_mask_loss: 0.1682tcmalloc: large alloc 1207705600 bytes == 0x564b7563a000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b57606000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 353s 7s/step - loss: 0.4320 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.1126 - mrcnn_class_loss: 0.0421 - mrcnn_bbox_loss: 0.1019 - mrcnn_mask_loss: 0.1692 - val_loss: 1.8755 - val_rpn_class_loss: 0.0572 - val_rpn_bbox_loss: 1.2440 - val_mrcnn_class_loss: 0.0962 - val_mrcnn_bbox_loss: 0.2567 - val_mrcnn_mask_loss: 0.2215\n",
            "Epoch 11/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.4059 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.1107 - mrcnn_class_loss: 0.0349 - mrcnn_bbox_loss: 0.0928 - mrcnn_mask_loss: 0.1611tcmalloc: large alloc 1207705600 bytes == 0x564b77078000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b5909e000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "50/50 [==============================] - 360s 7s/step - loss: 0.4067 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.1095 - mrcnn_class_loss: 0.0345 - mrcnn_bbox_loss: 0.0935 - mrcnn_mask_loss: 0.1628 - val_loss: 1.8925 - val_rpn_class_loss: 0.0694 - val_rpn_bbox_loss: 1.3167 - val_mrcnn_class_loss: 0.0533 - val_mrcnn_bbox_loss: 0.2351 - val_mrcnn_mask_loss: 0.2179\n",
            "Epoch 12/25\n",
            "49/50 [============================>.] - ETA: 2s - loss: 0.4095 - rpn_class_loss: 0.0054 - rpn_bbox_loss: 0.1279 - mrcnn_class_loss: 0.0302 - mrcnn_bbox_loss: 0.0916 - mrcnn_mask_loss: 0.1544tcmalloc: large alloc 1207705600 bytes == 0x564b71e48000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7c08 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n",
            "tcmalloc: large alloc 1207705600 bytes == 0x564b755ea000 @  0x7fd8e88871e7 0x7fd8e61db631 0x7fd8e6242470 0x7fd8e62cffb7 0x564ad40e5160 0x564ad41d6d4d 0x564ad4158ec8 0x564ad40e67aa 0x564ad41548f6 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153a2e 0x564ad40e688a 0x564ad4155719 0x564ad4153cdd 0x564ad40e688a 0x564ad4155719 0x564ad41d7b76 0x564ad4152e6a 0x564ad40e4ff9 0x564ad40e4ef0 0x564ad41589a3 0x564ad4153cdd 0x564ad4025eb0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6\n",
        "\n",
        "Download saved weights.\n",
        "\n",
        "This step is helpful when using Google Colab. As weights are automatically saved, it is useful to automatically download them from the Colab directory. These are found in _../logs_.\n",
        "\n",
        "Weights are automatically saved. If using Google Colab, it is useful to download these weights automatically."
      ],
      "metadata": {
        "id": "DHeFnD7Rrwc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "for fold in os.listdir(\"../logs\"):\n",
        "  # 1) Find all files:\n",
        "  vals = []\n",
        "  try:\n",
        "    for file in os.listdir(\"../logs/\"+fold):\n",
        "      vals.append(\"../logs/\"+fold+'/'+file)\n",
        "  except:\n",
        "    vals.append(\"../logs/\"+fold)\n",
        "  # 2) Filter files:\n",
        "  final_vals = []\n",
        "  for u in vals:\n",
        "    if (\"label\" in u) and (\"h5\" in u):\n",
        "      final_vals.append(u)\n",
        "  # 3) Download weights:\n",
        "  files.download(final_vals[-1]) "
      ],
      "metadata": {
        "id": "fgreHKWwrn6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UOvoxh-Ov23J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}