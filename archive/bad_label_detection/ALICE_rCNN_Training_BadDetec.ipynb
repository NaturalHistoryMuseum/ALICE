{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LittleAri/ALICE/blob/main/ALICE_rCNN_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeuepQudH8H7"
      },
      "source": [
        "# Mask RCNN Training for ALICE\n",
        "\n",
        "## Bad Label Detection\n",
        "\n",
        "Train model ([Mask RCNN](https://github.com/matterport/Mask_RCNN)) on good and bad merged labels. This is multiclass classification.\n",
        "\n",
        "This notebook is a copy of the notebook used to train the CNN to find labels in images, except the aim of this one is to detect bad labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G3w5PHWCPzT"
      },
      "source": [
        "#### Step 0\n",
        "Mount Google Drive.\n",
        "\n",
        "This step is useful if using Google Colab, as it's often easier to save documents there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c1P7lEJCUdI",
        "outputId": "ebf6c2b3-652a-43a0-c89f-d891043d2acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JP0iQWmh1i5"
      },
      "source": [
        "#### Step 1\n",
        "\n",
        "Check that images have loaded properly.\n",
        "\n",
        "This is a precautionary step which is helpful when using Google Colab, to check if images have been uploaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTaLNu8qfkTv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import skimage.io as io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "criJLe5mgxRp",
        "outputId": "74f5d364-14ea-41c2-db9b-a25f226fb5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['val', 65, 0]\n"
          ]
        }
      ],
      "source": [
        "errors = 0\n",
        "non_errors = 0\n",
        "\n",
        "for nm in os.listdir(\"drive/My Drive/ALICE/balloon/train\"):\n",
        "  if \"json\" not in nm:\n",
        "    try:\n",
        "      image = io.imread(\"drive/My Drive/ALICE/balloon/train/\"+nm)\n",
        "      non_errors = non_errors+1\n",
        "    except:\n",
        "      print(nm)\n",
        "      errors = errors+1\n",
        "\n",
        "print([\"val\",non_errors,errors])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = 0\n",
        "non_errors = 0\n",
        "\n",
        "for nm in os.listdir(\"balloon/train\"):\n",
        "  if \"json\" not in nm:\n",
        "    try:\n",
        "      image = io.imread(\"balloon/train/\"+nm)\n",
        "      non_errors = non_errors+1\n",
        "    except:\n",
        "      print(nm)\n",
        "      errors = errors+1\n",
        "\n",
        "print([\"val\",non_errors,errors])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veXAba6DGj-j",
        "outputId": "d605f226-254a-4558-b785-2ae55f113a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['val', 456, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ylGCol8h7rI"
      },
      "source": [
        "#### Step 2\n",
        "\n",
        "Import certain versions of Python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eztjdoJ6h7Nw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e94a61e-9a8d-4605-b494-30279d7716de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.48.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 42.4 MB/s \n",
            "\u001b[?25hCollecting h5py<=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.8.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=89c75ed0f094c202c3c33de1fae0a675f3569512046e14bfaa2441bbf996f02c\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: numpy, h5py, tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "jaxlib 0.3.15+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.17 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.1.0\n",
            "  Downloading Keras-2.1.0-py2.py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (1.7.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.0) (6.0)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "Successfully installed keras-2.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-empk1w_o\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-empk1w_o\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.7.3)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101077 sha256=5576ead410b94d1872f3277fd2e1dba505044e852571cb1c4c5ae3145e174a5a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l05shzeo/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 15.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 1.15.5 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.15.5\n",
            "  Downloading tensorflow_gpu-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0 MB 24 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.48.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.2.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Using cached numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.5) (1.14.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (3.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.5) (3.8.1)\n",
            "Installing collected packages: numpy, tensorflow-gpu\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "jaxlib 0.3.15+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.17 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.18.5 tensorflow-gpu-1.15.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-image==0.16.2\n",
            "  Downloading scikit_image-0.16.2-cp37-cp37m-manylinux1_x86_64.whl (26.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.9.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.7.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.3.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image==0.16.2) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.15.0)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "Successfully installed scikit-image-0.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.15.5\n",
        "!pip install keras==2.1.0\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install numpy==1.21.5\n",
        "!pip install tensorflow-gpu==1.15.5\n",
        "!pip install scikit-image==0.16.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf3AJmqNrJN5"
      },
      "source": [
        "#### Step 3:\n",
        "Import libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n3eSD54g4TX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mrcnn import *\n",
        "# import utils\n",
        "# import  visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import final\n",
        "#from model import log\n",
        "import skimage\n",
        "#from google.colab import files as files_\n",
        "import os\n",
        "import tensorflow as tf\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irrkMIZArcZB"
      },
      "source": [
        "#### Step 4\n",
        "\n",
        "Double check if there's a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFI-DWSfrRcG",
        "outputId": "86a0491e-359d-4de2-bb13-f49cf5e94242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kyL68Tvrh-J"
      },
      "source": [
        "#### Step 5\n",
        "\n",
        "Train model by building on top of pre-trained weights.\n",
        "\n",
        "The path for the images / labels that will be used for trianing, should be specified in _folder_for_labels_. The path to the folder containing the model and the pre-trained weights should be specified in _folder_for_model_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WsvpdlWrftZ",
        "outputId": "6095569f-b760-479f-cbf5-1c200fb54a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "Weights:  coco\n",
            "Dataset:  drive/MyDrive/ALICE/balloon\n",
            "Logs:  /logs\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                15\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           object\n",
            "NUM_CLASSES                    3\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:492: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:63: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3630: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3458: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1822: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "Downloading pretrained model to /mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n",
            "Loading weights  /mask_rcnn_coco.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:158: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:163: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-10-03 12:58:09.805189: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-10-03 12:58:09.810399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2022-10-03 12:58:09.810619: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xac652c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-10-03 12:58:09.810653: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-10-03 12:58:09.812321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-10-03 12:58:09.903591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-10-03 12:58:09.904479: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xac65640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-10-03 12:58:09.904519: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2022-10-03 12:58:09.904710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-10-03 12:58:09.905352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-10-03 12:58:09.905688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-10-03 12:58:09.906817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-10-03 12:58:09.908003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-10-03 12:58:09.908385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-10-03 12:58:09.909666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-10-03 12:58:09.910598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-10-03 12:58:09.913638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-10-03 12:58:09.913755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-10-03 12:58:09.914408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-10-03 12:58:09.915013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-10-03 12:58:09.915087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-10-03 12:58:09.916500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-10-03 12:58:09.916531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-10-03 12:58:09.916543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-10-03 12:58:09.916664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-10-03 12:58:09.917281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-10-03 12:58:09.917868: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-10-03 12:58:09.917912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14768 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:172: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:188: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['bad']\n",
            "numids [2]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "objects: ['good']\n",
            "numids [1]\n",
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /logs/object20221003T1258/mask_rcnn_object_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:953: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:675: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:940: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2039: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "Epoch 1/30\n",
            "2022-10-03 12:59:15.472227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-10-03 12:59:16.495229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.1711 - rpn_class_loss: 0.0110 - rpn_bbox_loss: 0.2588 - mrcnn_class_loss: 0.1397 - mrcnn_bbox_loss: 0.3998 - mrcnn_mask_loss: 0.3618/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2197: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:791: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "100/100 [==============================] - 178s 2s/step - loss: 1.1648 - rpn_class_loss: 0.0109 - rpn_bbox_loss: 0.2571 - mrcnn_class_loss: 0.1385 - mrcnn_bbox_loss: 0.3988 - mrcnn_mask_loss: 0.3596 - val_loss: 0.7757 - val_rpn_class_loss: 0.0089 - val_rpn_bbox_loss: 0.2756 - val_mrcnn_class_loss: 0.0576 - val_mrcnn_bbox_loss: 0.2595 - val_mrcnn_mask_loss: 0.1741\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 88s 879ms/step - loss: 0.4707 - rpn_class_loss: 0.0038 - rpn_bbox_loss: 0.1882 - mrcnn_class_loss: 0.0366 - mrcnn_bbox_loss: 0.1018 - mrcnn_mask_loss: 0.1402 - val_loss: 0.5273 - val_rpn_class_loss: 0.0074 - val_rpn_bbox_loss: 0.2724 - val_mrcnn_class_loss: 0.0451 - val_mrcnn_bbox_loss: 0.1112 - val_mrcnn_mask_loss: 0.0912\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 88s 883ms/step - loss: 0.3087 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.1407 - mrcnn_class_loss: 0.0270 - mrcnn_bbox_loss: 0.0560 - mrcnn_mask_loss: 0.0816 - val_loss: 0.4767 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.2606 - val_mrcnn_class_loss: 0.0471 - val_mrcnn_bbox_loss: 0.0979 - val_mrcnn_mask_loss: 0.0646\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 88s 883ms/step - loss: 0.2517 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.1188 - mrcnn_class_loss: 0.0233 - mrcnn_bbox_loss: 0.0430 - mrcnn_mask_loss: 0.0640 - val_loss: 0.4655 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.2518 - val_mrcnn_class_loss: 0.0468 - val_mrcnn_bbox_loss: 0.0924 - val_mrcnn_mask_loss: 0.0691\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 89s 889ms/step - loss: 0.2079 - rpn_class_loss: 0.0030 - rpn_bbox_loss: 0.0930 - mrcnn_class_loss: 0.0192 - mrcnn_bbox_loss: 0.0328 - mrcnn_mask_loss: 0.0599 - val_loss: 0.4768 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.2896 - val_mrcnn_class_loss: 0.0467 - val_mrcnn_bbox_loss: 0.0791 - val_mrcnn_mask_loss: 0.0558\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 88s 878ms/step - loss: 0.1957 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0923 - mrcnn_class_loss: 0.0170 - mrcnn_bbox_loss: 0.0274 - mrcnn_mask_loss: 0.0566 - val_loss: 0.4846 - val_rpn_class_loss: 0.0064 - val_rpn_bbox_loss: 0.2933 - val_mrcnn_class_loss: 0.0467 - val_mrcnn_bbox_loss: 0.0772 - val_mrcnn_mask_loss: 0.0612\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 88s 880ms/step - loss: 0.1750 - rpn_class_loss: 0.0029 - rpn_bbox_loss: 0.0712 - mrcnn_class_loss: 0.0166 - mrcnn_bbox_loss: 0.0245 - mrcnn_mask_loss: 0.0598 - val_loss: 0.4316 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.2513 - val_mrcnn_class_loss: 0.0512 - val_mrcnn_bbox_loss: 0.0642 - val_mrcnn_mask_loss: 0.0592\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 88s 884ms/step - loss: 0.1565 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0605 - mrcnn_class_loss: 0.0177 - mrcnn_bbox_loss: 0.0227 - mrcnn_mask_loss: 0.0532 - val_loss: 0.4936 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.2949 - val_mrcnn_class_loss: 0.0593 - val_mrcnn_bbox_loss: 0.0682 - val_mrcnn_mask_loss: 0.0651\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 89s 886ms/step - loss: 0.1535 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0591 - mrcnn_class_loss: 0.0179 - mrcnn_bbox_loss: 0.0217 - mrcnn_mask_loss: 0.0523 - val_loss: 0.5214 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.3290 - val_mrcnn_class_loss: 0.0570 - val_mrcnn_bbox_loss: 0.0722 - val_mrcnn_mask_loss: 0.0575\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 88s 882ms/step - loss: 0.1341 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0479 - mrcnn_class_loss: 0.0177 - mrcnn_bbox_loss: 0.0181 - mrcnn_mask_loss: 0.0478 - val_loss: 0.4531 - val_rpn_class_loss: 0.0069 - val_rpn_bbox_loss: 0.2620 - val_mrcnn_class_loss: 0.0541 - val_mrcnn_bbox_loss: 0.0761 - val_mrcnn_mask_loss: 0.0540\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 90s 896ms/step - loss: 0.1355 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0496 - mrcnn_class_loss: 0.0167 - mrcnn_bbox_loss: 0.0177 - mrcnn_mask_loss: 0.0494 - val_loss: 0.4930 - val_rpn_class_loss: 0.0066 - val_rpn_bbox_loss: 0.2943 - val_mrcnn_class_loss: 0.0608 - val_mrcnn_bbox_loss: 0.0670 - val_mrcnn_mask_loss: 0.0644\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 90s 903ms/step - loss: 0.1172 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0399 - mrcnn_class_loss: 0.0149 - mrcnn_bbox_loss: 0.0134 - mrcnn_mask_loss: 0.0471 - val_loss: 0.4796 - val_rpn_class_loss: 0.0045 - val_rpn_bbox_loss: 0.2846 - val_mrcnn_class_loss: 0.0603 - val_mrcnn_bbox_loss: 0.0743 - val_mrcnn_mask_loss: 0.0558\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 90s 899ms/step - loss: 0.1171 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0410 - mrcnn_class_loss: 0.0146 - mrcnn_bbox_loss: 0.0142 - mrcnn_mask_loss: 0.0452 - val_loss: 0.4758 - val_rpn_class_loss: 0.0056 - val_rpn_bbox_loss: 0.2770 - val_mrcnn_class_loss: 0.0675 - val_mrcnn_bbox_loss: 0.0710 - val_mrcnn_mask_loss: 0.0548\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 90s 901ms/step - loss: 0.1009 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0316 - mrcnn_class_loss: 0.0129 - mrcnn_bbox_loss: 0.0122 - mrcnn_mask_loss: 0.0420 - val_loss: 0.4785 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.2744 - val_mrcnn_class_loss: 0.0676 - val_mrcnn_bbox_loss: 0.0721 - val_mrcnn_mask_loss: 0.0578\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 89s 893ms/step - loss: 0.0972 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0270 - mrcnn_class_loss: 0.0134 - mrcnn_bbox_loss: 0.0131 - mrcnn_mask_loss: 0.0417 - val_loss: 0.4790 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.2820 - val_mrcnn_class_loss: 0.0604 - val_mrcnn_bbox_loss: 0.0758 - val_mrcnn_mask_loss: 0.0546\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 90s 902ms/step - loss: 0.0960 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0316 - mrcnn_class_loss: 0.0110 - mrcnn_bbox_loss: 0.0127 - mrcnn_mask_loss: 0.0383 - val_loss: 0.4772 - val_rpn_class_loss: 0.0074 - val_rpn_bbox_loss: 0.2822 - val_mrcnn_class_loss: 0.0661 - val_mrcnn_bbox_loss: 0.0684 - val_mrcnn_mask_loss: 0.0531\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 91s 907ms/step - loss: 0.0929 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0333 - mrcnn_class_loss: 0.0091 - mrcnn_bbox_loss: 0.0109 - mrcnn_mask_loss: 0.0378 - val_loss: 0.4735 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.2882 - val_mrcnn_class_loss: 0.0628 - val_mrcnn_bbox_loss: 0.0608 - val_mrcnn_mask_loss: 0.0554\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 90s 902ms/step - loss: 0.0791 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0194 - mrcnn_class_loss: 0.0093 - mrcnn_bbox_loss: 0.0109 - mrcnn_mask_loss: 0.0374 - val_loss: 0.4624 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.2699 - val_mrcnn_class_loss: 0.0698 - val_mrcnn_bbox_loss: 0.0628 - val_mrcnn_mask_loss: 0.0550\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 89s 890ms/step - loss: 0.0754 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0192 - mrcnn_class_loss: 0.0091 - mrcnn_bbox_loss: 0.0080 - mrcnn_mask_loss: 0.0368 - val_loss: 0.4656 - val_rpn_class_loss: 0.0067 - val_rpn_bbox_loss: 0.2690 - val_mrcnn_class_loss: 0.0648 - val_mrcnn_bbox_loss: 0.0667 - val_mrcnn_mask_loss: 0.0583\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 90s 896ms/step - loss: 0.0733 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0170 - mrcnn_class_loss: 0.0098 - mrcnn_bbox_loss: 0.0073 - mrcnn_mask_loss: 0.0372 - val_loss: 0.4584 - val_rpn_class_loss: 0.0046 - val_rpn_bbox_loss: 0.2638 - val_mrcnn_class_loss: 0.0637 - val_mrcnn_bbox_loss: 0.0660 - val_mrcnn_mask_loss: 0.0602\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 91s 914ms/step - loss: 0.0690 - rpn_class_loss: 0.0019 - rpn_bbox_loss: 0.0163 - mrcnn_class_loss: 0.0102 - mrcnn_bbox_loss: 0.0068 - mrcnn_mask_loss: 0.0337 - val_loss: 0.4705 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.2755 - val_mrcnn_class_loss: 0.0577 - val_mrcnn_bbox_loss: 0.0699 - val_mrcnn_mask_loss: 0.0617\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 90s 898ms/step - loss: 0.0679 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0155 - mrcnn_class_loss: 0.0110 - mrcnn_bbox_loss: 0.0067 - mrcnn_mask_loss: 0.0334 - val_loss: 0.4645 - val_rpn_class_loss: 0.0048 - val_rpn_bbox_loss: 0.2688 - val_mrcnn_class_loss: 0.0661 - val_mrcnn_bbox_loss: 0.0622 - val_mrcnn_mask_loss: 0.0625\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 90s 902ms/step - loss: 0.0610 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0107 - mrcnn_class_loss: 0.0096 - mrcnn_bbox_loss: 0.0057 - mrcnn_mask_loss: 0.0332 - val_loss: 0.5109 - val_rpn_class_loss: 0.0067 - val_rpn_bbox_loss: 0.3091 - val_mrcnn_class_loss: 0.0660 - val_mrcnn_bbox_loss: 0.0666 - val_mrcnn_mask_loss: 0.0625\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 90s 903ms/step - loss: 0.0616 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0130 - mrcnn_class_loss: 0.0099 - mrcnn_bbox_loss: 0.0060 - mrcnn_mask_loss: 0.0310 - val_loss: 0.4764 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.2854 - val_mrcnn_class_loss: 0.0637 - val_mrcnn_bbox_loss: 0.0621 - val_mrcnn_mask_loss: 0.0598\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 89s 895ms/step - loss: 0.0528 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0090 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.0040 - mrcnn_mask_loss: 0.0295 - val_loss: 0.4539 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.2536 - val_mrcnn_class_loss: 0.0678 - val_mrcnn_bbox_loss: 0.0631 - val_mrcnn_mask_loss: 0.0643\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 90s 902ms/step - loss: 0.0583 - rpn_class_loss: 0.0022 - rpn_bbox_loss: 0.0097 - mrcnn_class_loss: 0.0095 - mrcnn_bbox_loss: 0.0053 - mrcnn_mask_loss: 0.0316 - val_loss: 0.4965 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.2929 - val_mrcnn_class_loss: 0.0729 - val_mrcnn_bbox_loss: 0.0610 - val_mrcnn_mask_loss: 0.0635\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 91s 907ms/step - loss: 0.0527 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0084 - mrcnn_class_loss: 0.0082 - mrcnn_bbox_loss: 0.0052 - mrcnn_mask_loss: 0.0289 - val_loss: 0.4919 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.2913 - val_mrcnn_class_loss: 0.0674 - val_mrcnn_bbox_loss: 0.0628 - val_mrcnn_mask_loss: 0.0642\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 89s 893ms/step - loss: 0.0558 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0092 - mrcnn_class_loss: 0.0091 - mrcnn_bbox_loss: 0.0057 - mrcnn_mask_loss: 0.0302 - val_loss: 0.5196 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.3067 - val_mrcnn_class_loss: 0.0754 - val_mrcnn_bbox_loss: 0.0660 - val_mrcnn_mask_loss: 0.0657\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 90s 897ms/step - loss: 0.0593 - rpn_class_loss: 0.0013 - rpn_bbox_loss: 0.0158 - mrcnn_class_loss: 0.0085 - mrcnn_bbox_loss: 0.0060 - mrcnn_mask_loss: 0.0277 - val_loss: 0.4768 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.2706 - val_mrcnn_class_loss: 0.0778 - val_mrcnn_bbox_loss: 0.0598 - val_mrcnn_mask_loss: 0.0622\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 90s 904ms/step - loss: 0.0489 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0075 - mrcnn_class_loss: 0.0085 - mrcnn_bbox_loss: 0.0046 - mrcnn_mask_loss: 0.0264 - val_loss: 0.4959 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.2842 - val_mrcnn_class_loss: 0.0709 - val_mrcnn_bbox_loss: 0.0566 - val_mrcnn_mask_loss: 0.0781\n"
          ]
        }
      ],
      "source": [
        "!python3 final.py train --dataset=drive/MyDrive/ALICE/balloon --weights=coco"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_WJl_xRa_FB-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}