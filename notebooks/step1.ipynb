{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd21104e-d04e-48b7-9030-24e44c4fda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask matching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba02519b-d26f-45aa-9450-9cf2dfe22b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import cv2\n",
    "# from source_functions.demo import resize_image, colour_pin_mask, find_top_label\n",
    "# from source_functions.main import find_aligned_label\n",
    "# from source_functions.alignment_helper_functions import adjust_alignment\n",
    "# from source_functions.label_merging import align_merged_label, new_corners\n",
    "\n",
    "\n",
    "def return_image(id__, i, image_table, sample_pth, size_limit=2048):\n",
    "    im = image_table[\n",
    "        (image_table[\"id\"] == id__) & (image_table[\"image_index\"] == i + 1)\n",
    "    ][\"path\"].iloc[0]\n",
    "    try:\n",
    "        img = io.imread(sample_pth + \"/\" + im)\n",
    "    except:\n",
    "        try:\n",
    "            img = io.imread(sample_pth + \"/\" + im[:-4] + \"JPG\")\n",
    "        except:\n",
    "            img = io.imread(sample_pth + \"/\" + im[:-4] + \"jpg\")\n",
    "    if np.shape(img)[1] > size_limit:\n",
    "        img = resize_image(im)\n",
    "    return img\n",
    "\n",
    "\n",
    "def overlap_exclusion(msk_to_exclude_, msk_to_include_, tst):\n",
    "    msk_to_exclude = tst[msk_to_exclude_]\n",
    "    msk_to_include = tst[msk_to_include_]\n",
    "    msk_to_exclude_edit = deepcopy(msk_to_exclude)\n",
    "    msk_to_exclude_edit[np.where(msk_to_include == True)] = False\n",
    "    return msk_to_exclude_edit\n",
    "\n",
    "\n",
    "def review_overlaps(masks, filter_masks=True):\n",
    "\n",
    "    n_ = np.shape(masks)[0]\n",
    "\n",
    "    overlaps = []\n",
    "    for i in range(n_):\n",
    "        msk1 = masks[i]\n",
    "        N1 = len(np.where(msk1 == True)[0])\n",
    "        for j in range(i + 1, n_):\n",
    "            msk2 = masks[j]\n",
    "            N2 = len(np.where(msk2 == True)[0])\n",
    "            N_overlap = len(np.where((msk1 == True) & (msk2 == True))[0])\n",
    "            R1 = np.round(N_overlap / N1, 4)\n",
    "            R2 = np.round(N_overlap / N2, 4)\n",
    "            if (N_overlap != 0) and ((R1 > 0.15) or (R2 > 0.15)):\n",
    "                overlaps.append([i, j, R1, R2, N_overlap])\n",
    "\n",
    "    overlaps_sorted = deepcopy(overlaps)\n",
    "    overlaps_sorted = sorted(overlaps_sorted, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    masks_new = deepcopy(masks)\n",
    "\n",
    "    for o in overlaps_sorted:\n",
    "        msk1 = masks_new[o[0]]\n",
    "        msk2 = masks_new[o[1]]\n",
    "        N_overlap = len(np.where((msk1 == True) & (msk2 == True))[0])\n",
    "        R1 = np.round(N_overlap / len(np.where(msk1 == True)[0]), 4)\n",
    "        R2 = np.round(N_overlap / len(np.where(msk2 == True)[0]), 4)\n",
    "\n",
    "        msk_to_exclude_ = [o[0], o[1]][np.argmax([R1, R2])]\n",
    "        msk_to_include_ = [o[0], o[1]][np.argmin([R1, R2])]\n",
    "\n",
    "        new_mask = overlap_exclusion(msk_to_exclude_, msk_to_include_, masks_new)\n",
    "\n",
    "        masks_new[msk_to_exclude_] = new_mask\n",
    "\n",
    "    for i in range(n_):\n",
    "        msk_orig = masks[i]\n",
    "        msk_new = masks_new[i]\n",
    "        n1 = len(np.where(msk_orig == True)[0])\n",
    "        n2 = len(np.where(msk_new == True)[0])\n",
    "        r = n2 / n1\n",
    "        if (filter_masks == True) and (r < 0.1):\n",
    "            masks_new[i] = np.full(np.shape(masks_new[i]), False)\n",
    "\n",
    "    return masks_new, len(overlaps)\n",
    "\n",
    "\n",
    "def remove_small_masks(mask, limit=1000):\n",
    "    masks_filtered = []\n",
    "    for m in mask:\n",
    "        p = len(np.where(m == True)[0])\n",
    "        if p > limit:\n",
    "            masks_filtered.append(m)\n",
    "    return masks_filtered\n",
    "\n",
    "\n",
    "def make_matches(midpoints, temp_midpoints):\n",
    "    differences = {}\n",
    "    matches_ind = {}\n",
    "    for y in np.sort(temp_midpoints):\n",
    "        v = abs(midpoints - y)\n",
    "        differences[y] = v\n",
    "        j = np.argmin(v)\n",
    "        if j not in matches_ind.values():\n",
    "            matches_ind[y] = j\n",
    "        else:\n",
    "            ky = [k for k in matches_ind.keys() if matches_ind[k] == j][0]\n",
    "            diffs = differences[ky]\n",
    "            p1 = diffs[j]\n",
    "            p2 = v[j]\n",
    "            if p1 <= p2:\n",
    "                # original chosen match remains, but we choose the second closest match for current y\n",
    "                j = np.argsort(v)[1]\n",
    "                matches_ind[y] = j\n",
    "            else:\n",
    "                # change the original match, but keep the current match for the current y\n",
    "                j_ = np.argsort(v)[1]\n",
    "                matches_ind[y] = j\n",
    "                matches_ind[ky] = j_\n",
    "\n",
    "    return matches_ind\n",
    "\n",
    "\n",
    "def make_matches_v2(matches_to_be_found, template_to_match):\n",
    "    iterations = list(\n",
    "        itertools.permutations(matches_to_be_found, len(template_to_match))\n",
    "    )\n",
    "    iterations_indices = list(\n",
    "        itertools.permutations(enumerate(matches_to_be_found), len(template_to_match))\n",
    "    )\n",
    "    diffsum = [sum(abs(np.array(I) - np.sort(template_to_match))) for I in iterations]\n",
    "    argmin = np.argmin(diffsum)\n",
    "    matches = iterations[argmin]\n",
    "    index = iterations_indices[argmin]\n",
    "    matched_dict = {}\n",
    "    for u, t in enumerate(np.sort(template_to_match)):\n",
    "        matched_dict[t] = index[u][0]\n",
    "    return matched_dict\n",
    "\n",
    "\n",
    "def get_matched_masks_and_images(\n",
    "    id__,\n",
    "    image_table,\n",
    "    all_info,\n",
    "    mask_direc,\n",
    "    sample_pth,\n",
    "    max_no_labels=6,\n",
    "    limit=1000,\n",
    "    match_method=1,\n",
    "):\n",
    "\n",
    "    # 1) Get all masks for all images\n",
    "    details_dict = {}\n",
    "    msk_paths = image_table[image_table[\"id\"] == id__][\"mask_file\"]\n",
    "\n",
    "    for i, pth in enumerate(msk_paths):\n",
    "        details_dict.update({i: {\"mask_p\": []}})\n",
    "        bla = np.load(mask_direc + \"/\" + pth, allow_pickle=True)\n",
    "        details_dict[i][\"mask_p\"] = bla\n",
    "\n",
    "    # 2) Handle overlaps in masks\n",
    "    all_images_ = []\n",
    "    all_masks_ = []\n",
    "    for q in range(0, 4):\n",
    "        v = all_info[id__][q + 1]\n",
    "        img_ = return_image(id__, q, image_table, sample_pth)\n",
    "        tst = details_dict[v][\"mask_p\"]\n",
    "\n",
    "        masks_new, _ = review_overlaps(tst)\n",
    "\n",
    "        all_images_.append(img_)\n",
    "        all_masks_.append(masks_new)\n",
    "\n",
    "    # 3) Filter out small masks\n",
    "    new_masks_ = [remove_small_masks(m, limit=limit) for m in all_masks_]\n",
    "\n",
    "    # 4) Get number of masks to look at\n",
    "    filtered_msk_count = [len(m) for m in new_masks_]\n",
    "    min_count = min([min(filtered_msk_count), max_no_labels])\n",
    "\n",
    "    # 5) Pick template\n",
    "    k = np.argmin(filtered_msk_count)\n",
    "    template_ = new_masks_[k]\n",
    "    temp_vals = [len(np.where(m == True)[0]) for m in template_]\n",
    "    template_sorted = np.array(template_)[np.argsort(temp_vals)[::-1][:min_count]]\n",
    "\n",
    "    # 6) Find midpoint of masks in template\n",
    "    yvals_temp = [\n",
    "        sum([min(np.where(m == True)[0]), max(np.where(m == True)[0])]) / 2\n",
    "        for m in template_sorted\n",
    "    ]\n",
    "\n",
    "    # 7) Compare midpoints of all masks to template\n",
    "    final_label_masks = []\n",
    "    for i in range(4):\n",
    "        yv = [\n",
    "            sum([min(np.where(m == True)[0]), max(np.where(m == True)[0])]) / 2\n",
    "            for m in new_masks_[i]\n",
    "        ]\n",
    "        if match_method == 1:\n",
    "            matches = make_matches(yv, yvals_temp)\n",
    "        else:\n",
    "            matches = make_matches_v2(yv, yvals_temp)\n",
    "\n",
    "        msk_ = [new_masks_[i][p] for p in matches.values()]\n",
    "\n",
    "        final_label_masks.append(msk_)\n",
    "\n",
    "    return all_images_, final_label_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66962ef-42b1-4573-9ffb-34348677fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alice.config import PROCESSING_INPUT_DIR\n",
    "from alice.predict import predict_masks\n",
    "paths = [PROCESSING_INPUT_DIR / f'011245996_additional_{i}.jpeg' for i in range(1,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0074fd16-2519-4494-90ec-706fd5c5c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [cv2.imread(str(image_path)) for image_path in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f06cb7d1-1f9a-4e23-8108-7e5a8160a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "from alice.config import MODEL_DIR, EVAL_DIR\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = str(MODEL_DIR / \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9   # set testing threshold\n",
    "cfg.MODEL.DEVICE='cpu'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (label)\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59cf7b6f-f3e2-49d7-b7ba-5593c3bdc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_labels_from_image_path(image):\n",
    "    # Input: image\n",
    "    # Output: masks (np.array)\n",
    "    outputs = predictor(image)\n",
    "    label_masks = outputs[\"instances\"].to(\"cpu\").pred_masks\n",
    "    return label_masks, image\n",
    "\n",
    "all_original_masks = []\n",
    "\n",
    "# Step 1: Get Images / Masks\n",
    "############################\n",
    "\n",
    "for image in all_images:\n",
    "    label_masks = segment_labels_from_image_path(image)\n",
    "    all_original_masks.append(label_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "394626bb-6a0f-4e47-89bc-15edd9883b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "584b3485-5987-4460-b26a-32567af71672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]]), array([[[163, 169, 174],\n",
      "        [163, 169, 174],\n",
      "        [163, 169, 174],\n",
      "        ...,\n",
      "        [161, 170, 174],\n",
      "        [160, 169, 173],\n",
      "        [160, 169, 173]],\n",
      "\n",
      "       [[164, 170, 175],\n",
      "        [163, 169, 174],\n",
      "        [163, 169, 174],\n",
      "        ...,\n",
      "        [160, 169, 173],\n",
      "        [160, 169, 173],\n",
      "        [160, 169, 173]],\n",
      "\n",
      "       [[161, 167, 172],\n",
      "        [162, 168, 173],\n",
      "        [162, 168, 173],\n",
      "        ...,\n",
      "        [161, 170, 174],\n",
      "        [161, 170, 174],\n",
      "        [160, 169, 173]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[184, 184, 178],\n",
      "        [184, 184, 178],\n",
      "        [183, 183, 177],\n",
      "        ...,\n",
      "        [181, 180, 176],\n",
      "        [178, 179, 175],\n",
      "        [177, 178, 174]],\n",
      "\n",
      "       [[184, 184, 178],\n",
      "        [183, 183, 177],\n",
      "        [184, 184, 178],\n",
      "        ...,\n",
      "        [181, 180, 176],\n",
      "        [178, 179, 175],\n",
      "        [178, 179, 175]],\n",
      "\n",
      "       [[183, 183, 177],\n",
      "        [184, 184, 178],\n",
      "        [184, 184, 178],\n",
      "        ...,\n",
      "        [181, 180, 176],\n",
      "        [178, 179, 175],\n",
      "        [178, 179, 175]]], dtype=uint8)), (tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]]), array([[[160, 162, 172],\n",
      "        [157, 159, 169],\n",
      "        [159, 162, 170],\n",
      "        ...,\n",
      "        [147, 155, 162],\n",
      "        [146, 154, 161],\n",
      "        [146, 154, 161]],\n",
      "\n",
      "       [[159, 161, 171],\n",
      "        [159, 162, 170],\n",
      "        [159, 162, 170],\n",
      "        ...,\n",
      "        [147, 155, 162],\n",
      "        [146, 154, 161],\n",
      "        [146, 154, 161]],\n",
      "\n",
      "       [[158, 161, 169],\n",
      "        [158, 162, 167],\n",
      "        [159, 163, 168],\n",
      "        ...,\n",
      "        [146, 154, 161],\n",
      "        [147, 155, 162],\n",
      "        [147, 155, 162]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[173, 170, 166],\n",
      "        [174, 171, 167],\n",
      "        [173, 170, 166],\n",
      "        ...,\n",
      "        [169, 169, 169],\n",
      "        [167, 170, 168],\n",
      "        [168, 171, 169]],\n",
      "\n",
      "       [[175, 172, 168],\n",
      "        [173, 170, 166],\n",
      "        [172, 169, 165],\n",
      "        ...,\n",
      "        [167, 168, 166],\n",
      "        [168, 171, 169],\n",
      "        [169, 172, 170]],\n",
      "\n",
      "       [[173, 170, 166],\n",
      "        [173, 170, 166],\n",
      "        [173, 170, 166],\n",
      "        ...,\n",
      "        [168, 169, 167],\n",
      "        [167, 168, 166],\n",
      "        [169, 170, 166]]], dtype=uint8)), (tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]]), array([[[152, 164, 168],\n",
      "        [153, 165, 169],\n",
      "        [156, 168, 172],\n",
      "        ...,\n",
      "        [152, 158, 165],\n",
      "        [154, 157, 165],\n",
      "        [152, 155, 163]],\n",
      "\n",
      "       [[152, 164, 168],\n",
      "        [154, 166, 170],\n",
      "        [154, 166, 170],\n",
      "        ...,\n",
      "        [150, 156, 163],\n",
      "        [153, 156, 164],\n",
      "        [154, 157, 165]],\n",
      "\n",
      "       [[154, 166, 170],\n",
      "        [155, 167, 171],\n",
      "        [153, 165, 169],\n",
      "        ...,\n",
      "        [151, 160, 164],\n",
      "        [153, 159, 164],\n",
      "        [152, 158, 163]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[190, 191, 182],\n",
      "        [191, 192, 183],\n",
      "        [190, 193, 184],\n",
      "        ...,\n",
      "        [185, 186, 177],\n",
      "        [184, 185, 176],\n",
      "        [184, 185, 176]],\n",
      "\n",
      "       [[188, 189, 180],\n",
      "        [189, 190, 181],\n",
      "        [189, 192, 183],\n",
      "        ...,\n",
      "        [183, 184, 175],\n",
      "        [184, 185, 176],\n",
      "        [183, 184, 175]],\n",
      "\n",
      "       [[187, 188, 179],\n",
      "        [189, 190, 181],\n",
      "        [191, 192, 183],\n",
      "        ...,\n",
      "        [184, 185, 175],\n",
      "        [184, 185, 175],\n",
      "        [183, 184, 174]]], dtype=uint8))]\n"
     ]
    }
   ],
   "source": [
    "def review_overlaps(masks, filter_masks=True):\n",
    "\n",
    "    masks = masks[0]\n",
    "    \n",
    "    n_ = np.shape(masks)[0]\n",
    "\n",
    "    print(n_)\n",
    "\n",
    "    overlaps = []\n",
    "    for i in range(n_):\n",
    "        msk1 = masks[i]\n",
    "        N1 = len(np.where(msk1 == True)[0])\n",
    "        for j in range(i + 1, n_):\n",
    "            msk2 = masks[j]\n",
    "            N2 = len(np.where(msk2 == True)[0])\n",
    "            N_overlap = len(np.where((msk1 == True) & (msk2 == True))[0])\n",
    "            R1 = np.round(N_overlap / N1, 4)\n",
    "            R2 = np.round(N_overlap / N2, 4)\n",
    "            if (N_overlap != 0) and ((R1 > 0.15) or (R2 > 0.15)):\n",
    "                overlaps.append([i, j, R1, R2, N_overlap])\n",
    "\n",
    "    overlaps_sorted = deepcopy(overlaps)\n",
    "    overlaps_sorted = sorted(overlaps_sorted, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    masks_new = deepcopy(masks)\n",
    "\n",
    "    for o in overlaps_sorted:\n",
    "        msk1 = masks_new[o[0]]\n",
    "        msk2 = masks_new[o[1]]\n",
    "        N_overlap = len(np.where((msk1 == True) & (msk2 == True))[0])\n",
    "        R1 = np.round(N_overlap / len(np.where(msk1 == True)[0]), 4)\n",
    "        R2 = np.round(N_overlap / len(np.where(msk2 == True)[0]), 4)\n",
    "\n",
    "        msk_to_exclude_ = [o[0], o[1]][np.argmax([R1, R2])]\n",
    "        msk_to_include_ = [o[0], o[1]][np.argmin([R1, R2])]\n",
    "\n",
    "        new_mask = overlap_exclusion(msk_to_exclude_, msk_to_include_, masks_new)\n",
    "\n",
    "        masks_new[msk_to_exclude_] = new_mask\n",
    "\n",
    "    for i in range(n_):\n",
    "        msk_orig = masks[i]\n",
    "        msk_new = masks_new[i]\n",
    "        n1 = len(np.where(msk_orig == True)[0])\n",
    "        n2 = len(np.where(msk_new == True)[0])\n",
    "        r = n2 / n1\n",
    "        if (filter_masks == True) and (r < 0.1):\n",
    "            masks_new[i] = np.full(np.shape(masks_new[i]), False)\n",
    "\n",
    "    return masks_new, len(overlaps)\n",
    "\n",
    "MAX_NUMBER_OF_LABELS = 6\n",
    "\n",
    "def match_labels_across_images(all_masks, max_no_labels=MAX_NUMBER_OF_LABELS):\n",
    "    # Input: all masks across all 4 images. (np.array)\n",
    "    # Output: filtered masks across all 4 images. (np.array)\n",
    "\n",
    "    # 1) Filter masks and remove overlapping regions:\n",
    "    # all_masks_edited = []  # set of masks after potential overlaps were removed.\n",
    "    # for masks in all_masks:\n",
    "    #     masks_new, _ = review_overlaps(masks)  # remove overlaps between masks\n",
    "    #     print(masks_new)\n",
    "    #     # masks_new = remove_small_masks(\n",
    "    #     #     masks_new, limit=1500\n",
    "    #     # )  # exclude masks that are too small.\n",
    "    #     all_masks_edited.append(masks_new)\n",
    "\n",
    "    # print(len(all_masks_edited))\n",
    "\n",
    "    all_masks_edited = deepcopy(all_masks)\n",
    "\n",
    "    # 2) Define number of labels to look at:\n",
    "    # Note that this number will be less than the maximum number of labels defined with the variable max_no_labels.\n",
    "    filtered_msk_count = [\n",
    "        len(m) for m in all_masks_edited\n",
    "    ]  # Count of filtered masks per image.\n",
    "    min_count = min(\n",
    "        [min(filtered_msk_count), max_no_labels]\n",
    "    )  # Select number based on image with the fewest remaining labels.\n",
    "\n",
    "    # 3) Select template image/mask:\n",
    "    # The masks will be matched across images, based on a template.\n",
    "    k = np.argmin(filtered_msk_count)\n",
    "    print(k)\n",
    "\n",
    "    # template = all_masks_edited[k]\n",
    "    # template_mask_sizes = [len(np.where(m == True)[0]) for m in template]\n",
    "    # template_sorted = np.array(template)[\n",
    "    #     np.argsort(template_mask_sizes)[::-1][:min_count]\n",
    "    # ]  # sort template based on mask size.\n",
    "\n",
    "    # # 4) Find midpoints of masks in template:\n",
    "    # template_mask_midpoints_y = [\n",
    "    #     sum([min(np.where(m == True)[0]), max(np.where(m == True)[0])]) / 2\n",
    "    #     for m in template_sorted\n",
    "    # ]\n",
    "\n",
    "    # # 5) Compare midpoints of all masks to template:\n",
    "    # all_final_masks = []\n",
    "    # for i in range(4):\n",
    "    #     mask_midpoints_y = [\n",
    "    #         sum([min(np.where(m == True)[0]), max(np.where(m == True)[0])]) / 2\n",
    "    #         for m in all_masks_edited[i]\n",
    "    #     ]\n",
    "    #     label_matches_index = make_matches_v2(\n",
    "    #         mask_midpoints_y, template_mask_midpoints_y\n",
    "    #     )  # match labels based on the y coordinate of the midpoints.\n",
    "    #     matched_masks = [all_masks_edited[i][p] for p in label_matches_index.values()]\n",
    "    #     all_final_masks.append(matched_masks)\n",
    "\n",
    "    # return all_final_masks    \n",
    "\n",
    "# def get_merged_labels_from_ALICE(all_images):\n",
    "    # Input: 4 images obtained with ALICE hardware of one pinned specimen.\n",
    "    # Output: Merged versions of each label on specimen (up to a maximum number*), and transformed (aligned) labels from each image, for each label.\n",
    "    # *the maximum number is set with variable MAX_NUMBER_OF_LABELS in all_steps.py.\n",
    "\n",
    "\n",
    "\n",
    "# print(all_original_masks)\n",
    "\n",
    "all_masks = match_labels_across_images(all_original_masks)\n",
    "\n",
    "# all_results = get_merged_labels_from_ALICE(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05225858-92d2-4d09-a5de-819fd2f9c0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALICE",
   "language": "python",
   "name": "alice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
